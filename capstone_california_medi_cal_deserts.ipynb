{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Mapping Medi-Cal Deserts in California: Medi-Cal Intensity, Primary Care Capacity, Shortage Designations, and Preventable Hospitalizations (PQI)\n",
        "\n",
        "## Project Overview\n",
        "\n",
        "This notebook builds a county-year panel for California that links:\n",
        "1. Medi-Cal enrollment intensity (need/exposure)\n",
        "2. Primary care access proxies: physician supply (patient-care hours dataset) + primary care shortage designation\n",
        "3. Outcomes: preventable hospitalizations (AHRQ PQI by county-year)\n",
        "4. Controls: ACS demographics/economic/education covariates\n",
        "\n",
        "**Main Questions:**\n",
        "1. Where are Medi-Cal \"deserts\" in California (high Medi-Cal share + low primary care capacity and/or shortage designation)?\n",
        "2. Are deserts associated with worse outcomes (higher preventable hospitalization rates)?\n",
        "3. Do changes in Medi-Cal intensity correlate with changes in outcomes and capacity over time?\n",
        "\n",
        "**Scope:** California counties only (58 counties)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0) Setup & Reproducibility"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "import os\n",
        "from pathlib import Path\n",
        "import re\n",
        "\n",
        "# Statistical modeling\n",
        "try:\n",
        "    from linearmodels import PanelOLS\n",
        "    HAS_PANELOLS = True\n",
        "except ImportError:\n",
        "    HAS_PANELOLS = False\n",
        "    print(\"WARNING: linearmodels not available. Will use statsmodels with dummies.\")\n",
        "    from statsmodels.regression.linear_model import OLS\n",
        "    import statsmodels.api as sm\n",
        "\n",
        "# Optional: geopandas for maps (only if shapefile exists)\n",
        "try:\n",
        "    import geopandas as gpd\n",
        "    HAS_GEOPANDAS = True\n",
        "except ImportError:\n",
        "    HAS_GEOPANDAS = False\n",
        "    print(\"WARNING: geopandas not available. Maps will be skipped.\")\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set display options\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', 100)\n",
        "pd.set_option('display.width', 200)\n",
        "\n",
        "print(\"Setup complete.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create output directories\n",
        "output_dirs = ['outputs', 'outputs/data', 'outputs/figures', 'outputs/tables']\n",
        "for dir_path in output_dirs:\n",
        "    os.makedirs(dir_path, exist_ok=True)\n",
        "    print(f\"Created/verified: {dir_path}/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Helper Functions\n",
        "\n",
        "def standardize_county_name(name):\n",
        "    \"\"\"Standardize county name for merging.\"\"\"\n",
        "    if pd.isna(name):\n",
        "        return None\n",
        "    name = str(name).upper()\n",
        "    # Remove \"County, California\" and similar suffixes\n",
        "    name = re.sub(r',?\\s*CALIFORNIA\\s*$', '', name)\n",
        "    name = re.sub(r'\\s+COUNTY\\s*$', '', name)\n",
        "    name = re.sub(r'\\s+', ' ', name).strip()\n",
        "    # Remove punctuation\n",
        "    name = re.sub(r'[^\\w\\s]', '', name)\n",
        "    return name\n",
        "\n",
        "def make_fips5(state_fips, county_fips3):\n",
        "    \"\"\"Create 5-digit FIPS code.\"\"\"\n",
        "    state_str = str(int(state_fips)).zfill(2)\n",
        "    county_str = str(int(county_fips3)).zfill(3)\n",
        "    return state_str + county_str\n",
        "\n",
        "def safe_read_csv(filepath, **kwargs):\n",
        "    \"\"\"Safely read CSV with error handling.\"\"\"\n",
        "    try:\n",
        "        return pd.read_csv(filepath, **kwargs)\n",
        "    except Exception as e:\n",
        "        print(f\"ERROR reading {filepath}: {e}\")\n",
        "        raise\n",
        "\n",
        "def safe_read_excel(filepath, **kwargs):\n",
        "    \"\"\"Safely read Excel with error handling.\"\"\"\n",
        "    try:\n",
        "        return pd.read_excel(filepath, **kwargs)\n",
        "    except Exception as e:\n",
        "        print(f\"ERROR reading {filepath}: {e}\")\n",
        "        raise\n",
        "\n",
        "def assert_expected_columns(df, expected_cols, filepath):\n",
        "    \"\"\"Check that expected columns exist.\"\"\"\n",
        "    missing = set(expected_cols) - set(df.columns)\n",
        "    if missing:\n",
        "        raise ValueError(f\"Missing columns in {filepath}: {missing}\")\n",
        "    print(f\"✓ All expected columns present in {filepath}\")\n",
        "\n",
        "def summarize_missingness(df, name=\"Dataset\"):\n",
        "    \"\"\"Print missingness summary.\"\"\"\n",
        "    missing = df.isnull().sum()\n",
        "    missing_pct = (missing / len(df)) * 100\n",
        "    summary = pd.DataFrame({\n",
        "        'Missing_Count': missing,\n",
        "        'Missing_Pct': missing_pct\n",
        "    })\n",
        "    summary = summary[summary['Missing_Count'] > 0].sort_values('Missing_Count', ascending=False)\n",
        "    if len(summary) > 0:\n",
        "        print(f\"\\nMissingness in {name}:\")\n",
        "        print(summary)\n",
        "    else:\n",
        "        print(f\"\\n✓ No missing values in {name}\")\n",
        "    return summary\n",
        "\n",
        "def merge_report(left, right, on, how='inner', left_name='Left', right_name='Right'):\n",
        "    \"\"\"Report merge results.\"\"\"\n",
        "    merged = pd.merge(left, right, on=on, how=how, indicator=True)\n",
        "    print(f\"\\nMerge: {left_name} + {right_name} on {on} ({how})\")\n",
        "    print(f\"  Left rows: {len(left)}\")\n",
        "    print(f\"  Right rows: {len(right)}\")\n",
        "    print(f\"  Merged rows: {len(merged)}\")\n",
        "    if '_merge' in merged.columns:\n",
        "        merge_counts = merged['_merge'].value_counts()\n",
        "        print(f\"  Merge status:\")\n",
        "        for status, count in merge_counts.items():\n",
        "            print(f\"    {status}: {count}\")\n",
        "    return merged\n",
        "\n",
        "print(\"Helper functions defined.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Load Raw Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Required files - Updated to match actual data structure\n",
        "# Note: county name.xlsx is not a crosswalk - we'll build crosswalk from ACS data\n",
        "REQUIRED_FILES = [\n",
        "    'medi-cal-enrollment-dashboard-data.csv',\n",
        "    'E4 estiamtes.xlsx',\n",
        "    'physicians-actively-working-by-specialty-and-patient-care-hours.xlsx',\n",
        "    'Primary CAre Shortage .csv',\n",
        "    'PQI.csv',\n",
        "    'demoACS.csv',\n",
        "    'educACS.csv',\n",
        "    'EconACS.csv'\n",
        "]\n",
        "\n",
        "# Check for required files\n",
        "missing_files = []\n",
        "for f in REQUIRED_FILES:\n",
        "    if not os.path.exists(f):\n",
        "        missing_files.append(f)\n",
        "    else:\n",
        "        print(f\"✓ Found: {f}\")\n",
        "\n",
        "if missing_files:\n",
        "    raise FileNotFoundError(f\"Missing required files: {missing_files}\")\n",
        "\n",
        "print(f\"\\n✓ All {len(REQUIRED_FILES)} required files found.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load required files\n",
        "print(\"Loading required files...\\n\")\n",
        "\n",
        "# Medi-Cal enrollment\n",
        "df_medical_dash = safe_read_csv('medi-cal-enrollment-dashboard-data.csv', low_memory=False)\n",
        "print(f\"medi-cal-enrollment-dashboard-data.csv: {df_medical_dash.shape}\")\n",
        "print(f\"Columns: {list(df_medical_dash.columns)}\\n\")\n",
        "\n",
        "# Population estimates - Load from correct sheet with proper headers\n",
        "df_e4_raw = pd.read_excel('E4 estiamtes.xlsx', sheet_name='Table 1 County State', header=None)\n",
        "print(f\"E4 estiamtes.xlsx (raw): {df_e4_raw.shape}\")\n",
        "print(df_e4_raw.head(10))\n",
        "print()\n",
        "\n",
        "# Physician supply\n",
        "df_physician = safe_read_excel('physicians-actively-working-by-specialty-and-patient-care-hours.xlsx')\n",
        "print(f\"physicians-actively-working-by-specialty-and-patient-care-hours.xlsx: {df_physician.shape}\")\n",
        "print(df_physician.head())\n",
        "print(f\"Columns: {list(df_physician.columns)}\\n\")\n",
        "\n",
        "# Shortage designation\n",
        "df_shortage = safe_read_csv('Primary CAre Shortage .csv', low_memory=False)\n",
        "print(f\"Primary CAre Shortage .csv: {df_shortage.shape}\")\n",
        "print(f\"Columns: {list(df_shortage.columns)}\\n\")\n",
        "\n",
        "# PQI outcomes\n",
        "df_pqi = safe_read_csv('PQI.csv', low_memory=False)\n",
        "print(f\"PQI.csv: {df_pqi.shape}\")\n",
        "print(f\"Columns: {list(df_pqi.columns)}\\n\")\n",
        "\n",
        "# ACS controls\n",
        "df_demo = safe_read_csv('demoACS.csv')\n",
        "print(f\"demoACS.csv: {df_demo.shape}\")\n",
        "print(f\"Columns: {list(df_demo.columns)}\\n\")\n",
        "\n",
        "df_educ = safe_read_csv('educACS.csv')\n",
        "print(f\"educACS.csv: {df_educ.shape}\")\n",
        "print(f\"Columns: {list(df_educ.columns)}\\n\")\n",
        "\n",
        "df_econ = safe_read_csv('EconACS.csv')\n",
        "print(f\"EconACS.csv: {df_econ.shape}\")\n",
        "print(f\"Columns: {list(df_econ.columns)}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optional files\n",
        "optional_files = {\n",
        "    'Medi-CAL.csv': None,\n",
        "    'pqi-physicians-specialities-list.xlsx': None,\n",
        "    'pqi-physicians-data-dictionary.csv': None,\n",
        "    'pqi-physicians-data-set.csv': None,\n",
        "    'physicians-actively-working-by-specialty-and-administration-activity-hours.xlsx': None,\n",
        "    'physicians-actively-working-by-specialty-and-other-activity-hours.xlsx': None,\n",
        "    'physicians-actively-working-by-specialty-and-research-activity-hours.xlsx': None,\n",
        "    'physicians-actively-working-by-specialty-and-training-activity-hours.xlsx': None\n",
        "}\n",
        "\n",
        "for fname in optional_files.keys():\n",
        "    if os.path.exists(fname):\n",
        "        try:\n",
        "            if fname.endswith('.csv'):\n",
        "                optional_files[fname] = safe_read_csv(fname, low_memory=False)\n",
        "            else:\n",
        "                optional_files[fname] = safe_read_excel(fname)\n",
        "            print(f\"✓ Loaded optional: {fname} ({optional_files[fname].shape})\")\n",
        "        except Exception as e:\n",
        "            print(f\"⚠ Could not load optional {fname}: {e}\")\n",
        "    else:\n",
        "        print(f\"⊘ Optional file not found: {fname} (will skip)\")\n",
        "\n",
        "# Store specialty list if available\n",
        "df_specialty_list = optional_files.get('pqi-physicians-specialities-list.xlsx')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Build Clean County Crosswalk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build county crosswalk from ACS data (which has county names and FIPS codes)\n",
        "# The ACS files have: NAME, state, county columns where state=6 (CA) and county is 3-digit FIPS\n",
        "\n",
        "print(\"Building county crosswalk from ACS data...\")\n",
        "print(f\"ACS demo data: {df_demo.shape}\")\n",
        "print(df_demo.head())\n",
        "\n",
        "# California FIPS codes - official list (58 counties)\n",
        "# Standard California county FIPS codes\n",
        "CA_COUNTY_FIPS = {\n",
        "    'ALAMEDA': '001', 'ALPINE': '003', 'AMADOR': '005', 'BUTTE': '007', 'CALAVERAS': '009',\n",
        "    'COLUSA': '011', 'CONTRA COSTA': '013', 'DEL NORTE': '015', 'EL DORADO': '017', 'FRESNO': '019',\n",
        "    'GLENN': '021', 'HUMBOLDT': '023', 'IMPERIAL': '025', 'INYO': '027', 'KERN': '029',\n",
        "    'KINGS': '031', 'LAKE': '033', 'LASSEN': '035', 'LOS ANGELES': '037', 'MADERA': '039',\n",
        "    'MARIN': '041', 'MARIPOSA': '043', 'MENDOCINO': '045', 'MERCED': '047', 'MODOC': '049',\n",
        "    'MONO': '051', 'MONTEREY': '053', 'NAPA': '055', 'NEVADA': '057', 'ORANGE': '059',\n",
        "    'PLACER': '061', 'PLUMAS': '063', 'RIVERSIDE': '065', 'SACRAMENTO': '067', 'SAN BENITO': '069',\n",
        "    'SAN BERNARDINO': '071', 'SAN DIEGO': '073', 'SAN FRANCISCO': '075', 'SAN JOAQUIN': '077',\n",
        "    'SAN LUIS OBISPO': '079', 'SAN MATEO': '081', 'SANTA BARBARA': '083', 'SANTA CLARA': '085',\n",
        "    'SANTA CRUZ': '087', 'SHASTA': '089', 'SIERRA': '091', 'SISKIYOU': '093', 'SOLANO': '095',\n",
        "    'SONOMA': '097', 'STANISLAUS': '099', 'SUTTER': '101', 'TEHAMA': '103', 'TRINITY': '105',\n",
        "    'TULARE': '107', 'TUOLUMNE': '109', 'VENTURA': '111', 'YOLO': '113', 'YUBA': '115'\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build crosswalk from ACS data\n",
        "crosswalk_clean = df_demo[['NAME', 'state', 'county']].copy()\n",
        "\n",
        "# Create standardized county name\n",
        "crosswalk_clean['county_name_raw'] = crosswalk_clean['NAME'].astype(str)\n",
        "crosswalk_clean['county_name_clean'] = crosswalk_clean['county_name_raw'].apply(standardize_county_name)\n",
        "\n",
        "# State FIPS for California is always \"06\"\n",
        "crosswalk_clean['state_fips'] = \"06\"\n",
        "\n",
        "# County FIPS from ACS data (already has 3-digit county codes)\n",
        "crosswalk_clean['county_fips3'] = crosswalk_clean['county'].astype(str).str.zfill(3)\n",
        "\n",
        "# Create fips5\n",
        "crosswalk_clean['fips5'] = '06' + crosswalk_clean['county_fips3']\n",
        "\n",
        "# Keep only needed columns\n",
        "crosswalk_clean = crosswalk_clean[['county_name_raw', 'county_name_clean', 'county_fips3', 'state_fips', 'fips5']].copy()\n",
        "crosswalk_clean = crosswalk_clean.dropna(subset=['fips5'])\n",
        "crosswalk_clean = crosswalk_clean.drop_duplicates(subset=['fips5'])\n",
        "\n",
        "print(f\"\\nCrosswalk created: {len(crosswalk_clean)} counties\")\n",
        "print(f\"Unique fips5: {crosswalk_clean['fips5'].nunique()}\")\n",
        "print(\"\\nSample:\")\n",
        "print(crosswalk_clean.head(10))\n",
        "\n",
        "# Verify we have 58 CA counties\n",
        "if crosswalk_clean['fips5'].nunique() < 58:\n",
        "    print(f\"\\n⚠ WARNING: Only {crosswalk_clean['fips5'].nunique()} counties found. Expected 58.\")\n",
        "else:\n",
        "    print(f\"\\n✓ Found {crosswalk_clean['fips5'].nunique()} counties (expected 58)\")\n",
        "\n",
        "# Save\n",
        "crosswalk_clean.to_csv('outputs/data/county_crosswalk_clean.csv', index=False)\n",
        "print(\"\\n✓ Saved: outputs/data/county_crosswalk_clean.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Clean Population (E4 estimates)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Process E4 population data\n",
        "# The data is in wide format: County, Year1, Year2, etc.\n",
        "# Header row is row 2, data starts row 3\n",
        "\n",
        "print(\"Processing E4 population estimates...\")\n",
        "print(f\"Raw shape: {df_e4_raw.shape}\")\n",
        "print(df_e4_raw.head(5))\n",
        "\n",
        "# Find header row (row 2 has \"County\" and year labels)\n",
        "header_row = 2\n",
        "df_e4 = df_e4_raw.iloc[header_row:].copy()\n",
        "df_e4.columns = df_e4_raw.iloc[header_row].values\n",
        "\n",
        "# Clean column names\n",
        "df_e4.columns = [str(c).strip() for c in df_e4.columns]\n",
        "print(f\"\\nColumns after setting header: {df_e4.columns.tolist()}\")\n",
        "\n",
        "# Skip header row in data\n",
        "df_e4 = df_e4.iloc[1:].copy()\n",
        "\n",
        "# Get county column (first column)\n",
        "county_col = df_e4.columns[0]\n",
        "print(f\"County column: {county_col}\")\n",
        "\n",
        "# Identify year columns (date formats like 1/1/2021)\n",
        "year_cols = []\n",
        "for col in df_e4.columns[1:]:\n",
        "    try:\n",
        "        # Try to extract year from column name\n",
        "        if '/' in str(col):\n",
        "            year = int(str(col).split('/')[-1])\n",
        "            if 2000 <= year <= 2030:\n",
        "                year_cols.append((col, year))\n",
        "        elif str(col).isdigit() and len(str(col)) == 4:\n",
        "            year_cols.append((col, int(col)))\n",
        "    except:\n",
        "        continue\n",
        "\n",
        "print(f\"Year columns found: {year_cols}\")\n",
        "\n",
        "# Melt to long format\n",
        "if len(year_cols) > 0:\n",
        "    # Create mapping of column names to years\n",
        "    col_to_year = {col: year for col, year in year_cols}\n",
        "    \n",
        "    # Melt data\n",
        "    id_vars = [county_col]\n",
        "    value_vars = [col for col, year in year_cols]\n",
        "    \n",
        "    pop_long = pd.melt(df_e4, id_vars=id_vars, value_vars=value_vars, \n",
        "                       var_name='year_col', value_name='population')\n",
        "    pop_long['year'] = pop_long['year_col'].map(col_to_year)\n",
        "    pop_long['county_name_clean'] = pop_long[county_col].apply(standardize_county_name)\n",
        "    \n",
        "    # Merge with crosswalk to get FIPS\n",
        "    pop_year = pop_long.merge(crosswalk_clean[['county_name_clean', 'fips5']], \n",
        "                              on='county_name_clean', how='left')\n",
        "    \n",
        "    # Clean population column\n",
        "    pop_year['population'] = pd.to_numeric(pop_year['population'], errors='coerce')\n",
        "    \n",
        "    # Keep only needed columns\n",
        "    pop_year = pop_year[['fips5', 'year', 'population']].copy()\n",
        "    pop_year = pop_year.dropna(subset=['fips5', 'year', 'population'])\n",
        "else:\n",
        "    print(\"ERROR: Could not identify year columns\")\n",
        "    pop_year = pd.DataFrame(columns=['fips5', 'year', 'population'])\n",
        "\n",
        "print(f\"\\nPopulation data: {len(pop_year)} county-years\")\n",
        "if len(pop_year) > 0:\n",
        "    print(f\"Year range: {pop_year['year'].min():.0f} - {pop_year['year'].max():.0f}\")\n",
        "    print(f\"Unique counties: {pop_year['fips5'].nunique()}\")\n",
        "    print(\"\\nSample:\")\n",
        "    print(pop_year.head(10))\n",
        "else:\n",
        "    print(\"WARNING: No population data loaded!\")\n",
        "\n",
        "# Save\n",
        "pop_year.to_csv('outputs/data/pop_e4_clean.csv', index=False)\n",
        "print(\"\\n✓ Saved: outputs/data/pop_e4_clean.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Clean Medi-Cal Enrollment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Inspect Medi-Cal enrollment structure\n",
        "print(\"Medi-Cal enrollment columns:\", df_medical_dash.columns.tolist())\n",
        "print(\"\\nFirst few rows:\")\n",
        "print(df_medical_dash.head(10))\n",
        "\n",
        "# Identify key columns\n",
        "date_cols = [c for c in df_medical_dash.columns if 'date' in c.lower() or 'eligibility' in c.lower()]\n",
        "county_cols = [c for c in df_medical_dash.columns if 'county' in c.lower()]\n",
        "enroll_cols = [c for c in df_medical_dash.columns if 'enroll' in c.lower() or '#' in c.lower()]\n",
        "\n",
        "print(f\"\\nPotential date columns: {date_cols}\")\n",
        "print(f\"Potential county columns: {county_cols}\")\n",
        "print(f\"Potential enrollment columns: {enroll_cols}\")\n",
        "\n",
        "# Build enrollment dataset\n",
        "medical_raw = df_medical_dash.copy()\n",
        "\n",
        "# Extract county and standardize\n",
        "if len(county_cols) > 0:\n",
        "    county_col = county_cols[0]\n",
        "    medical_raw['county_name_clean'] = medical_raw[county_col].apply(standardize_county_name)\n",
        "    medical_raw = medical_raw.merge(crosswalk_clean[['county_name_clean', 'fips5']], on='county_name_clean', how='left')\n",
        "else:\n",
        "    print(\"ERROR: No county column found\")\n",
        "    medical_raw['fips5'] = None\n",
        "\n",
        "# Extract date and year\n",
        "if len(date_cols) > 0:\n",
        "    date_col = date_cols[0]\n",
        "    medical_raw['date'] = pd.to_datetime(medical_raw[date_col], errors='coerce')\n",
        "    medical_raw['year'] = medical_raw['date'].dt.year\n",
        "    medical_raw['month'] = medical_raw['date'].dt.month\n",
        "else:\n",
        "    print(\"WARNING: No date column found\")\n",
        "    medical_raw['year'] = None\n",
        "    medical_raw['month'] = None\n",
        "\n",
        "# Extract enrollment count\n",
        "if len(enroll_cols) > 0:\n",
        "    enroll_col = enroll_cols[0]\n",
        "    # Handle NULL values\n",
        "    medical_raw['enrollment'] = pd.to_numeric(medical_raw[enroll_col].replace('NULL', np.nan), errors='coerce')\n",
        "else:\n",
        "    print(\"ERROR: No enrollment column found\")\n",
        "    medical_raw['enrollment'] = np.nan\n",
        "\n",
        "# The data is at county-year-sex-age-ethnic-language level\n",
        "# First SUM across subgroups to get county-month total, then average across months\n",
        "# Step 1: Sum enrollment within each county-year-month\n",
        "medical_monthly = medical_raw.groupby(['fips5', 'year', 'month']).agg({\n",
        "    'enrollment': 'sum'  # Sum across all demographic subgroups\n",
        "}).reset_index()\n",
        "\n",
        "# Step 2: Average monthly enrollment within each year\n",
        "medical_year = medical_monthly.groupby(['fips5', 'year']).agg({\n",
        "    'enrollment': 'mean'  # Average monthly enrollment\n",
        "}).reset_index()\n",
        "medical_year = medical_year.rename(columns={'enrollment': 'medi_cal_enrollment'})\n",
        "medical_year = medical_year.dropna(subset=['fips5', 'year', 'medi_cal_enrollment'])\n",
        "\n",
        "print(f\"\\nMedi-Cal enrollment: {len(medical_year)} county-years\")\n",
        "print(f\"Year range: {medical_year['year'].min():.0f} - {medical_year['year'].max():.0f}\")\n",
        "print(f\"Unique counties: {medical_year['fips5'].nunique()}\")\n",
        "print(\"\\nSample:\")\n",
        "print(medical_year.head(10))\n",
        "\n",
        "# Merge with population to compute share\n",
        "medical_year = medical_year.merge(pop_year[['fips5', 'year', 'population']], on=['fips5', 'year'], how='left')\n",
        "medical_year['medi_cal_share'] = medical_year['medi_cal_enrollment'] / medical_year['population']\n",
        "\n",
        "print(f\"\\nAfter population merge: {len(medical_year)} county-years\")\n",
        "print(f\"Medi-Cal share range: {medical_year['medi_cal_share'].min():.4f} - {medical_year['medi_cal_share'].max():.4f}\")\n",
        "\n",
        "# Save\n",
        "medical_year.to_csv('outputs/data/medical_enrollment_clean.csv', index=False)\n",
        "print(\"\\n✓ Saved: outputs/data/medical_enrollment_clean.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Clean Physician Supply"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define primary care specialties\n",
        "# The pqi-physicians-specialities-list.xlsx maps conditions to specialties, not primary care definitions\n",
        "# Using standard primary care specialty definitions\n",
        "\n",
        "print(\"Defining primary care specialties...\")\n",
        "\n",
        "# Standard primary care specialties (based on AHRQ and common definitions)\n",
        "# Do NOT include subspecialties\n",
        "primary_care_specialties = {\n",
        "    'FAMILY MEDICINE', \n",
        "    'FAMILY PRACTICE',\n",
        "    'GENERAL PRACTICE',\n",
        "    'GENERAL INTERNAL MEDICINE', \n",
        "    'INTERNAL MEDICINE',\n",
        "    'GENERAL PEDIATRICS', \n",
        "    'PEDIATRICS',\n",
        "    'GERIATRIC MEDICINE'\n",
        "}\n",
        "\n",
        "# Check what specialties are actually in the physician data\n",
        "print(\"\\nSpecialties in physician data:\")\n",
        "actual_specialties = df_physician['Specialty'].str.upper().unique()\n",
        "print(actual_specialties[:20])\n",
        "\n",
        "# Match primary care specialties to what's actually in the data\n",
        "matched_specialties = set()\n",
        "for spec in actual_specialties:\n",
        "    spec_upper = str(spec).upper()\n",
        "    if any(pcp in spec_upper for pcp in ['FAMILY', 'INTERNAL MEDICINE', 'PEDIATRIC', 'GENERAL PRACTICE', 'GERIATRIC']):\n",
        "        # Exclude subspecialties\n",
        "        if not any(sub in spec_upper for sub in ['CARDIO', 'GASTRO', 'NEPHRO', 'PULMON', 'ONCOL', 'HEMATOL', 'INFECTIOUS', 'RHEUMAT', 'ENDOCRIN', 'CRITICAL']):\n",
        "            matched_specialties.add(spec_upper)\n",
        "\n",
        "# Use matched specialties if found, otherwise use defaults\n",
        "if len(matched_specialties) > 0:\n",
        "    primary_care_specialties = matched_specialties\n",
        "    print(f\"\\nMatched primary care specialties from data ({len(primary_care_specialties)}):\")\n",
        "else:\n",
        "    print(f\"\\nUsing default primary care specialties ({len(primary_care_specialties)}):\")\n",
        "\n",
        "for spec in sorted(primary_care_specialties):\n",
        "    print(f\"  - {spec}\")\n",
        "\n",
        "# Save specialty definition\n",
        "spec_df = pd.DataFrame({'specialty': sorted(primary_care_specialties)})\n",
        "spec_df.to_csv('outputs/tables/primary_care_specialty_definition.csv', index=False)\n",
        "print(\"\\n✓ Saved: outputs/tables/primary_care_specialty_definition.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Process physician supply data\n",
        "print(\"Physician supply columns:\", df_physician.columns.tolist())\n",
        "print(\"\\nFirst few rows:\")\n",
        "print(df_physician.head(10))\n",
        "\n",
        "# Build physician supply dataset\n",
        "physician_supply = df_physician.copy()\n",
        "\n",
        "# Extract county and match to FIPS\n",
        "physician_supply['county_name_clean'] = physician_supply['County'].apply(standardize_county_name)\n",
        "physician_supply = physician_supply.merge(crosswalk_clean[['county_name_clean', 'fips5']], on='county_name_clean', how='left')\n",
        "\n",
        "# No year column - data is time-invariant\n",
        "print(\"NOTE: No year column found - treating as time-invariant\")\n",
        "physician_supply['year'] = None\n",
        "IS_TIME_VARYING = False\n",
        "\n",
        "# Extract specialty  \n",
        "physician_supply['specialty_clean'] = physician_supply['Specialty'].astype(str).str.upper()\n",
        "\n",
        "# Extract count - use 'Estimated Count' column\n",
        "physician_supply['physician_count'] = pd.to_numeric(physician_supply['Estimated Count'], errors='coerce')\n",
        "\n",
        "print(f\"\\nTotal physician records: {len(physician_supply)}\")\n",
        "print(f\"Unique specialties: {physician_supply['specialty_clean'].nunique()}\")\n",
        "print(f\"Unique counties: {physician_supply['fips5'].nunique()}\")\n",
        "\n",
        "# Filter to primary care specialties\n",
        "physician_supply['is_primary_care'] = physician_supply['specialty_clean'].isin(primary_care_specialties)\n",
        "physician_pcp = physician_supply[physician_supply['is_primary_care']].copy()\n",
        "\n",
        "print(f\"\\nPrimary care physicians: {len(physician_pcp)} records\")\n",
        "print(f\"PCP unique counties: {physician_pcp['fips5'].nunique()}\")\n",
        "print(f\"Total PCP count: {physician_pcp['physician_count'].sum():.0f}\")\n",
        "\n",
        "# Aggregate to county level (sum all PCPs across activity levels)\n",
        "physician_agg = physician_pcp.groupby(['fips5']).agg({\n",
        "    'physician_count': 'sum'\n",
        "}).reset_index()\n",
        "physician_agg = physician_agg.rename(columns={'physician_count': 'pcp_supply'})\n",
        "\n",
        "print(f\"\\nAggregated to {len(physician_agg)} counties\")\n",
        "print(f\"PCP supply range: {physician_agg['pcp_supply'].min():.0f} - {physician_agg['pcp_supply'].max():.0f}\")\n",
        "\n",
        "# Merge with average population to compute per 100k\n",
        "pop_avg = pop_year.groupby('fips5')['population'].mean().reset_index()\n",
        "pop_avg = pop_avg.rename(columns={'population': 'avg_population'})\n",
        "physician_agg = physician_agg.merge(pop_avg, on='fips5', how='left')\n",
        "\n",
        "print(f\"\\nAfter population merge: {len(physician_agg)} counties\")\n",
        "print(f\"Population range: {physician_agg['avg_population'].min():.0f} - {physician_agg['avg_population'].max():.0f}\")\n",
        "\n",
        "# Compute per 100k\n",
        "physician_agg['pcp_per_100k'] = (physician_agg['pcp_supply'] / physician_agg['avg_population']) * 100000\n",
        "\n",
        "print(f\"PCP per 100k range: {physician_agg['pcp_per_100k'].min():.2f} - {physician_agg['pcp_per_100k'].max():.2f}\")\n",
        "\n",
        "# Save\n",
        "physician_agg.to_csv('outputs/data/physician_supply_clean.csv', index=False)\n",
        "print(\"\\n✓ Saved: outputs/data/physician_supply_clean.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6) Clean Shortage File"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Inspect shortage file structure\n",
        "print(\"Shortage file columns:\", df_shortage.columns.tolist())\n",
        "print(\"\\nFirst few rows:\")\n",
        "print(df_shortage.head(10))\n",
        "\n",
        "# Identify key columns\n",
        "county_cols = [c for c in df_shortage.columns if 'county' in c.lower() or 'cnty' in c.lower() or 'fips' in c.lower()]\n",
        "year_cols = [c for c in df_shortage.columns if 'year' in c.lower() or 'effective' in c.lower()]\n",
        "flag_cols = [c for c in df_shortage.columns if 'pcs' in c.lower() or 'shortage' in c.lower() or 'yes' in c.lower()]\n",
        "score_cols = [c for c in df_shortage.columns if 'score' in c.lower()]\n",
        "\n",
        "print(f\"\\nPotential county columns: {county_cols}\")\n",
        "print(f\"Potential year columns: {year_cols}\")\n",
        "print(f\"Potential flag columns: {flag_cols}\")\n",
        "print(f\"Potential score columns: {score_cols}\")\n",
        "\n",
        "# Build shortage dataset\n",
        "shortage_raw = df_shortage.copy()\n",
        "\n",
        "# Extract county FIPS\n",
        "if 'CNTY_FIPS' in shortage_raw.columns:\n",
        "    shortage_raw['county_fips3'] = pd.to_numeric(shortage_raw['CNTY_FIPS'], errors='coerce').astype(str).str.zfill(3)\n",
        "    shortage_raw['fips5'] = '06' + shortage_raw['county_fips3']\n",
        "elif len(county_cols) > 0:\n",
        "    county_col = county_cols[0]\n",
        "    if 'FIPS' in county_col.upper():\n",
        "        shortage_raw['county_fips3'] = pd.to_numeric(shortage_raw[county_col], errors='coerce').astype(str).str.zfill(3)\n",
        "        shortage_raw['fips5'] = '06' + shortage_raw['county_fips3']\n",
        "    else:\n",
        "        shortage_raw['county_name_clean'] = shortage_raw[county_col].apply(standardize_county_name)\n",
        "        shortage_raw = shortage_raw.merge(crosswalk_clean[['county_name_clean', 'fips5']], on='county_name_clean', how='left')\n",
        "else:\n",
        "    print(\"ERROR: Could not identify county column\")\n",
        "    shortage_raw['fips5'] = None\n",
        "\n",
        "# Extract year (if exists)\n",
        "if len(year_cols) > 0:\n",
        "    year_col = year_cols[0]\n",
        "    if 'effective' in year_col.lower():\n",
        "        # Parse date\n",
        "        shortage_raw['date'] = pd.to_datetime(shortage_raw[year_col], errors='coerce')\n",
        "        shortage_raw['year'] = shortage_raw['date'].dt.year\n",
        "    else:\n",
        "        shortage_raw['year'] = pd.to_numeric(shortage_raw[year_col], errors='coerce')\n",
        "else:\n",
        "    print(\"NOTE: No year column found - treating as time-invariant\")\n",
        "    shortage_raw['year'] = None\n",
        "\n",
        "# Extract shortage flag\n",
        "# PCSA column indicates Primary Care Service Area shortage designation\n",
        "if 'PCSA' in shortage_raw.columns:\n",
        "    shortage_raw['shortage_flag'] = (shortage_raw['PCSA'].astype(str).str.upper() == 'YES').astype(int)\n",
        "elif len(flag_cols) > 0:\n",
        "    flag_col = flag_cols[0]\n",
        "    shortage_raw['shortage_flag'] = (shortage_raw[flag_col].astype(str).str.upper().isin(['YES', 'TRUE', '1', 'Y'])).astype(int)\n",
        "else:\n",
        "    print(\"WARNING: Could not identify shortage flag column\")\n",
        "    shortage_raw['shortage_flag'] = 0\n",
        "\n",
        "# Extract score (if available)\n",
        "if len(score_cols) > 0:\n",
        "    score_col = [c for c in score_cols if 'total' in c.lower() or 'tota' in c.lower()]\n",
        "    if len(score_col) > 0:\n",
        "        shortage_raw['shortage_score'] = pd.to_numeric(shortage_raw[score_col[0]], errors='coerce')\n",
        "    else:\n",
        "        shortage_raw['shortage_score'] = pd.to_numeric(shortage_raw[score_cols[0]], errors='coerce')\n",
        "else:\n",
        "    shortage_raw['shortage_score'] = None\n",
        "\n",
        "# Aggregate to county-year (or county if no year)\n",
        "# If sub-county (MSSA level), aggregate by max(flag) and max(score)\n",
        "if shortage_raw['year'].notna().any():\n",
        "    shortage_agg = shortage_raw.groupby(['fips5', 'year']).agg({\n",
        "        'shortage_flag': 'max',\n",
        "        'shortage_score': 'max'\n",
        "    }).reset_index()\n",
        "    IS_SHORTAGE_TIME_VARYING = True\n",
        "else:\n",
        "    shortage_agg = shortage_raw.groupby(['fips5']).agg({\n",
        "        'shortage_flag': 'max',\n",
        "        'shortage_score': 'max'\n",
        "    }).reset_index()\n",
        "    IS_SHORTAGE_TIME_VARYING = False\n",
        "    print(\"\\n⚠ WARNING: Shortage designation is time-invariant. Will merge by county only.\")\n",
        "\n",
        "shortage_agg = shortage_agg.dropna(subset=['fips5'])\n",
        "\n",
        "print(f\"\\nShortage designation: {len(shortage_agg)} county{'s' if not IS_SHORTAGE_TIME_VARYING else '-years'}\")\n",
        "print(f\"Counties with shortage: {(shortage_agg['shortage_flag'] == 1).sum()}\")\n",
        "\n",
        "# Save\n",
        "shortage_agg.to_csv('outputs/data/shortage_clean.csv', index=False)\n",
        "print(\"\\n✓ Saved: outputs/data/shortage_clean.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clean demographic ACS\n",
        "print(\"Cleaning demoACS.csv...\")\n",
        "acs_demo = df_demo.copy()\n",
        "\n",
        "# Extract county name and standardize\n",
        "acs_demo['county_name_clean'] = acs_demo['NAME'].apply(standardize_county_name)\n",
        "acs_demo = acs_demo.merge(crosswalk_clean[['county_name_clean', 'fips5']], on='county_name_clean', how='left')\n",
        "\n",
        "# Extract required variables\n",
        "acs_demo['age65_pct'] = pd.to_numeric(acs_demo['DP05_0024PE'], errors='coerce')\n",
        "acs_demo['hispanic_pct'] = pd.to_numeric(acs_demo['DP05_0071PE'], errors='coerce')\n",
        "\n",
        "acs_demo_clean = acs_demo[['fips5', 'age65_pct', 'hispanic_pct']].copy()\n",
        "acs_demo_clean = acs_demo_clean.dropna(subset=['fips5'])\n",
        "\n",
        "print(f\"  Counties: {acs_demo_clean['fips5'].nunique()}\")\n",
        "\n",
        "# Clean education ACS\n",
        "print(\"\\nCleaning educACS.csv...\")\n",
        "acs_educ = df_educ.copy()\n",
        "\n",
        "acs_educ['county_name_clean'] = acs_educ['NAME'].apply(standardize_county_name)\n",
        "acs_educ = acs_educ.merge(crosswalk_clean[['county_name_clean', 'fips5']], on='county_name_clean', how='left')\n",
        "\n",
        "acs_educ['bachelors_pct'] = pd.to_numeric(acs_educ['DP02_0068PE'], errors='coerce')\n",
        "\n",
        "acs_educ_clean = acs_educ[['fips5', 'bachelors_pct']].copy()\n",
        "acs_educ_clean = acs_educ_clean.dropna(subset=['fips5'])\n",
        "\n",
        "print(f\"  Counties: {acs_educ_clean['fips5'].nunique()}\")\n",
        "\n",
        "# Clean economic ACS\n",
        "print(\"\\nCleaning EconACS.csv...\")\n",
        "acs_econ = df_econ.copy()\n",
        "\n",
        "acs_econ['county_name_clean'] = acs_econ['NAME'].apply(standardize_county_name)\n",
        "acs_econ = acs_econ.merge(crosswalk_clean[['county_name_clean', 'fips5']], on='county_name_clean', how='left')\n",
        "\n",
        "# Use only poverty_pct and unemp_pct (ignore income field)\n",
        "acs_econ['poverty_pct'] = pd.to_numeric(acs_econ['DP03_0128PE'], errors='coerce')\n",
        "acs_econ['unemp_pct'] = pd.to_numeric(acs_econ['DP03_0009PE'], errors='coerce')\n",
        "\n",
        "acs_econ_clean = acs_econ[['fips5', 'poverty_pct', 'unemp_pct']].copy()\n",
        "acs_econ_clean = acs_econ_clean.dropna(subset=['fips5'])\n",
        "\n",
        "print(f\"  Counties: {acs_econ_clean['fips5'].nunique()}\")\n",
        "\n",
        "# Merge all ACS controls\n",
        "acs_controls = acs_demo_clean.merge(acs_educ_clean, on='fips5', how='outer')\n",
        "acs_controls = acs_controls.merge(acs_econ_clean, on='fips5', how='outer')\n",
        "\n",
        "print(f\"\\nACS controls: {len(acs_controls)} counties\")\n",
        "print(f\"Variables: {list(acs_controls.columns)}\")\n",
        "print(\"\\nSample:\")\n",
        "print(acs_controls.head(10))\n",
        "\n",
        "# Save\n",
        "acs_controls.to_csv('outputs/data/acs_controls_clean.csv', index=False)\n",
        "print(\"\\n✓ Saved: outputs/data/acs_controls_clean.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8) Clean PQI and Build Outcomes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clean PQI data\n",
        "print(\"Cleaning PQI.csv...\")\n",
        "\n",
        "pqi_clean = df_pqi.copy()\n",
        "\n",
        "# Standardize county name\n",
        "pqi_clean['county_name_clean'] = pqi_clean['County'].apply(standardize_county_name)\n",
        "pqi_clean = pqi_clean.merge(crosswalk_clean[['county_name_clean', 'fips5']], on='county_name_clean', how='left')\n",
        "\n",
        "# Extract year\n",
        "pqi_clean['year'] = pd.to_numeric(pqi_clean['Year'], errors='coerce')\n",
        "\n",
        "# Convert all numeric columns first (handle commas in numbers)\n",
        "for col in ['Count_ICD9', 'Count_ICD10', 'Population_ICD9', 'Population_ICD10', \n",
        "            'ObsRate_ICD9', 'ObsRate_ICD10', 'RiskAdjRate_ICD9', 'RiskAdjRate_ICD10']:\n",
        "    if col in pqi_clean.columns:\n",
        "        pqi_clean[col] = pqi_clean[col].astype(str).str.replace(',', '').replace('nan', '')\n",
        "        pqi_clean[col] = pd.to_numeric(pqi_clean[col], errors='coerce')\n",
        "\n",
        "# Unify ICD-9 and ICD-10 fields\n",
        "# Use ICD-10 if not null, else ICD-9\n",
        "pqi_clean['pqi_count'] = pqi_clean['Count_ICD10'].fillna(pqi_clean['Count_ICD9'])\n",
        "pqi_clean['pqi_population'] = pqi_clean['Population_ICD10'].fillna(pqi_clean['Population_ICD9'])\n",
        "pqi_clean['obs_rate'] = pqi_clean['ObsRate_ICD10'].fillna(pqi_clean['ObsRate_ICD9'])\n",
        "pqi_clean['risk_adj_rate'] = pqi_clean['RiskAdjRate_ICD10'].fillna(pqi_clean['RiskAdjRate_ICD9'])\n",
        "\n",
        "# Main outcome: risk_adj_rate if available, else obs_rate\n",
        "pqi_clean['outcome_rate'] = pqi_clean['risk_adj_rate'].fillna(pqi_clean['obs_rate'])\n",
        "\n",
        "# Ensure numeric types\n",
        "pqi_clean['outcome_rate'] = pd.to_numeric(pqi_clean['outcome_rate'], errors='coerce')\n",
        "pqi_clean['pqi_count'] = pd.to_numeric(pqi_clean['pqi_count'], errors='coerce')\n",
        "pqi_clean['pqi_population'] = pd.to_numeric(pqi_clean['pqi_population'], errors='coerce')\n",
        "\n",
        "# Keep PQI identifier\n",
        "pqi_clean['pqi_id'] = pqi_clean['PQI']\n",
        "pqi_clean['pqi_name'] = pqi_clean['PQIDescription']\n",
        "\n",
        "# Create long format\n",
        "pqi_long_clean = pqi_clean[[\n",
        "    'fips5', 'year', 'pqi_id', 'pqi_name', \n",
        "    'outcome_rate', 'pqi_count', 'pqi_population'\n",
        "]].copy()\n",
        "pqi_long_clean = pqi_long_clean.dropna(subset=['fips5', 'year', 'outcome_rate'])\n",
        "\n",
        "print(f\"PQI long format: {len(pqi_long_clean)} county-year-PQI observations\")\n",
        "print(f\"Year range: {pqi_long_clean['year'].min():.0f} - {pqi_long_clean['year'].max():.0f}\")\n",
        "print(f\"Unique counties: {pqi_long_clean['fips5'].nunique()}\")\n",
        "print(f\"Unique PQI measures: {pqi_long_clean['pqi_id'].nunique()}\")\n",
        "print(f\"Outcome rate range: {pqi_long_clean['outcome_rate'].min():.2f} - {pqi_long_clean['outcome_rate'].max():.2f}\")\n",
        "\n",
        "# Save long format\n",
        "pqi_long_clean.to_csv('outputs/data/pqi_long_clean.csv', index=False)\n",
        "print(\"\\n✓ Saved: outputs/data/pqi_long_clean.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Aggregate to county-year (mean across all PQIs)\n",
        "pqi_county_year = pqi_long_clean.groupby(['fips5', 'year']).agg({\n",
        "    'outcome_rate': 'mean',\n",
        "    'pqi_count': 'sum',\n",
        "    'pqi_population': 'mean'  # Should be same across PQIs for same county-year\n",
        "}).reset_index()\n",
        "pqi_county_year = pqi_county_year.rename(columns={\n",
        "    'outcome_rate': 'pqi_mean_rate',\n",
        "    'pqi_count': 'pqi_sum_count',\n",
        "    'pqi_population': 'pqi_sum_population'\n",
        "})\n",
        "\n",
        "print(f\"PQI county-year: {len(pqi_county_year)} county-years\")\n",
        "print(f\"Year range: {pqi_county_year['year'].min():.0f} - {pqi_county_year['year'].max():.0f}\")\n",
        "print(f\"Unique counties: {pqi_county_year['fips5'].nunique()}\")\n",
        "print(f\"PQI mean rate range: {pqi_county_year['pqi_mean_rate'].min():.2f} - {pqi_county_year['pqi_mean_rate'].max():.2f}\")\n",
        "\n",
        "# Save\n",
        "pqi_county_year.to_csv('outputs/data/pqi_county_year_clean.csv', index=False)\n",
        "print(\"\\n✓ Saved: outputs/data/pqi_county_year_clean.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Merge plan\n",
        "print(\"=\" * 60)\n",
        "print(\"MERGE PLAN\")\n",
        "print(\"=\" * 60)\n",
        "print(\"\\nStarting with: pqi_county_year (fips5, year)\")\n",
        "print(\"Merge keys and intended final schema:\")\n",
        "print(\"  1. + pop_year (fips5, year) -> population\")\n",
        "print(\"  2. + medical_year (fips5, year) -> medi_cal_enrollment, medi_cal_share\")\n",
        "print(\"  3. + physician_agg (fips5, year or fips5) -> pcp_supply, pcp_per_100k\")\n",
        "print(\"  4. + shortage_agg (fips5, year or fips5) -> shortage_flag, shortage_score\")\n",
        "print(\"  5. + acs_controls (fips5) -> poverty_pct, unemp_pct, age65_pct, hispanic_pct, bachelors_pct\")\n",
        "print(\"\\nFinal panel: county-year with all variables\")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Start with PQI outcomes\n",
        "master_panel = pqi_county_year.copy()\n",
        "\n",
        "print(f\"Starting rows: {len(master_panel)}\")\n",
        "print(f\"Unique counties: {master_panel['fips5'].nunique()}\")\n",
        "print(f\"Year range: {master_panel['year'].min():.0f} - {master_panel['year'].max():.0f}\")\n",
        "\n",
        "# Merge population\n",
        "master_panel = merge_report(master_panel, pop_year, on=['fips5', 'year'], \n",
        "                           left_name='PQI', right_name='Population')\n",
        "master_panel = master_panel.drop(columns=['_merge'])\n",
        "\n",
        "# Merge Medi-Cal enrollment\n",
        "master_panel = merge_report(master_panel, medical_year[['fips5', 'year', 'medi_cal_enrollment', 'medi_cal_share']], \n",
        "                           on=['fips5', 'year'], left_name='Panel', right_name='Medi-Cal')\n",
        "master_panel = master_panel.drop(columns=['_merge'])\n",
        "\n",
        "# Merge physician supply\n",
        "if IS_TIME_VARYING:\n",
        "    master_panel = merge_report(master_panel, physician_agg[['fips5', 'year', 'pcp_supply', 'pcp_per_100k']], \n",
        "                               on=['fips5', 'year'], left_name='Panel', right_name='Physician Supply')\n",
        "else:\n",
        "    master_panel = merge_report(master_panel, physician_agg[['fips5', 'pcp_supply', 'pcp_per_100k']], \n",
        "                               on=['fips5'], left_name='Panel', right_name='Physician Supply')\n",
        "master_panel = master_panel.drop(columns=['_merge'])\n",
        "\n",
        "# Merge shortage\n",
        "if IS_SHORTAGE_TIME_VARYING:\n",
        "    master_panel = merge_report(master_panel, shortage_agg[['fips5', 'year', 'shortage_flag', 'shortage_score']], \n",
        "                               on=['fips5', 'year'], left_name='Panel', right_name='Shortage')\n",
        "else:\n",
        "    master_panel = merge_report(master_panel, shortage_agg[['fips5', 'shortage_flag', 'shortage_score']], \n",
        "                               on=['fips5'], left_name='Panel', right_name='Shortage')\n",
        "master_panel = master_panel.drop(columns=['_merge'])\n",
        "\n",
        "# Merge ACS controls (time-invariant)\n",
        "master_panel = merge_report(master_panel, acs_controls, on=['fips5'], \n",
        "                           left_name='Panel', right_name='ACS Controls')\n",
        "master_panel = master_panel.drop(columns=['_merge'])\n",
        "\n",
        "print(f\"\\nFinal panel: {len(master_panel)} county-years\")\n",
        "print(f\"Unique counties: {master_panel['fips5'].nunique()}\")\n",
        "print(f\"Year range: {master_panel['year'].min():.0f} - {master_panel['year'].max():.0f}\")\n",
        "\n",
        "# QA: Check missingness\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"MISSINGNESS REPORT\")\n",
        "print(\"=\" * 60)\n",
        "summarize_missingness(master_panel, \"Master Panel\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create desert definitions\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"CREATING DESERT DEFINITIONS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Define thresholds and quartiles for each year\n",
        "desert_panel = master_panel.copy()\n",
        "\n",
        "# For each year, compute quartiles and thresholds\n",
        "desert_panel['high_medi_cal_q'] = False\n",
        "desert_panel['low_pcp_q'] = False\n",
        "desert_panel['high_medi_cal_thr'] = False\n",
        "desert_panel['low_pcp_thr'] = False\n",
        "\n",
        "# Thresholds\n",
        "medi_cal_threshold = 0.30  # 30% Medi-Cal share\n",
        "# PCP threshold: choose based on distribution (e.g., bottom 25th percentile value)\n",
        "pcp_threshold = desert_panel['pcp_per_100k'].quantile(0.25)\n",
        "\n",
        "print(f\"Medi-Cal share threshold: {medi_cal_threshold}\")\n",
        "print(f\"PCP per 100k threshold: {pcp_threshold:.2f}\")\n",
        "\n",
        "for year in desert_panel['year'].unique():\n",
        "    year_mask = desert_panel['year'] == year\n",
        "    year_data = desert_panel[year_mask]\n",
        "    \n",
        "    # Quartile-based\n",
        "    medi_cal_q75 = year_data['medi_cal_share'].quantile(0.75)\n",
        "    pcp_q25 = year_data['pcp_per_100k'].quantile(0.25)\n",
        "    \n",
        "    desert_panel.loc[year_mask, 'high_medi_cal_q'] = desert_panel.loc[year_mask, 'medi_cal_share'] >= medi_cal_q75\n",
        "    desert_panel.loc[year_mask, 'low_pcp_q'] = desert_panel.loc[year_mask, 'pcp_per_100k'] <= pcp_q25\n",
        "    \n",
        "    # Threshold-based\n",
        "    desert_panel.loc[year_mask, 'high_medi_cal_thr'] = desert_panel.loc[year_mask, 'medi_cal_share'] >= medi_cal_threshold\n",
        "    desert_panel.loc[year_mask, 'low_pcp_thr'] = desert_panel.loc[year_mask, 'pcp_per_100k'] <= pcp_threshold\n",
        "\n",
        "# Create desert definitions\n",
        "# Definition 1: high Medi-Cal AND low PCP\n",
        "desert_panel['desert_q_def1'] = (desert_panel['high_medi_cal_q'] & desert_panel['low_pcp_q']).astype(int)\n",
        "desert_panel['desert_thr_def1'] = (desert_panel['high_medi_cal_thr'] & desert_panel['low_pcp_thr']).astype(int)\n",
        "\n",
        "# Definition 2: high Medi-Cal AND (low PCP OR shortage)\n",
        "desert_panel['desert_q_def2'] = (desert_panel['high_medi_cal_q'] & \n",
        "                                 (desert_panel['low_pcp_q'] | (desert_panel['shortage_flag'] == 1))).astype(int)\n",
        "desert_panel['desert_thr_def2'] = (desert_panel['high_medi_cal_thr'] & \n",
        "                                   (desert_panel['low_pcp_thr'] | (desert_panel['shortage_flag'] == 1))).astype(int)\n",
        "\n",
        "print(f\"\\nDesert counts (quartile-based, def1): {desert_panel['desert_q_def1'].sum()}\")\n",
        "print(f\"Desert counts (quartile-based, def2): {desert_panel['desert_q_def2'].sum()}\")\n",
        "print(f\"Desert counts (threshold-based, def1): {desert_panel['desert_thr_def1'].sum()}\")\n",
        "print(f\"Desert counts (threshold-based, def2): {desert_panel['desert_thr_def2'].sum()}\")\n",
        "\n",
        "# Update master panel\n",
        "master_panel = desert_panel.copy()\n",
        "\n",
        "# Save master panel\n",
        "master_panel.to_csv('outputs/data/ca_master_panel.csv', index=False)\n",
        "print(\"\\n✓ Saved: outputs/data/ca_master_panel.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create variable dictionary\n",
        "var_dict = pd.DataFrame([\n",
        "    ['fips5', '5-digit FIPS code (state + county)', 'county name.xlsx', 'code', 'No'],\n",
        "    ['year', 'Year', 'PQI.csv', 'year', 'Yes'],\n",
        "    ['pqi_mean_rate', 'Mean PQI rate (risk-adjusted if available, else observed)', 'PQI.csv', 'rate per 100k', 'Yes'],\n",
        "    ['pqi_sum_count', 'Total PQI counts', 'PQI.csv', 'count', 'Yes'],\n",
        "    ['pqi_sum_population', 'Population denominator for PQI', 'PQI.csv', 'count', 'Yes'],\n",
        "    ['population', 'County population', 'E4 estiamtes.xlsx', 'count', 'Yes'],\n",
        "    ['medi_cal_enrollment', 'Medi-Cal enrollment (annual average monthly)', 'medi-cal-enrollment-dashboard-data.csv', 'count', 'Yes'],\n",
        "    ['medi_cal_share', 'Medi-Cal enrollment / population', 'medi-cal-enrollment-dashboard-data.csv', 'proportion', 'Yes'],\n",
        "    ['pcp_supply', 'Primary care physician supply (count)', 'physicians-actively-working-by-specialty-and-patient-care-hours.xlsx', 'count', 'Yes' if IS_TIME_VARYING else 'No'],\n",
        "    ['pcp_per_100k', 'Primary care physicians per 100,000 population', 'physicians-actively-working-by-specialty-and-patient-care-hours.xlsx', 'rate', 'Yes' if IS_TIME_VARYING else 'No'],\n",
        "    ['shortage_flag', 'Primary care shortage designation (0/1)', 'Primary CAre Shortage .csv', 'binary', 'Yes' if IS_SHORTAGE_TIME_VARYING else 'No'],\n",
        "    ['shortage_score', 'Primary care shortage score', 'Primary CAre Shortage .csv', 'score', 'Yes' if IS_SHORTAGE_TIME_VARYING else 'No'],\n",
        "    ['poverty_pct', 'Percent below poverty line', 'EconACS.csv', 'percent', 'No'],\n",
        "    ['unemp_pct', 'Unemployment rate', 'EconACS.csv', 'percent', 'No'],\n",
        "    ['age65_pct', 'Percent age 65 and over', 'demoACS.csv', 'percent', 'No'],\n",
        "    ['hispanic_pct', 'Percent Hispanic', 'demoACS.csv', 'percent', 'No'],\n",
        "    ['bachelors_pct', 'Percent with bachelor degree or higher', 'educACS.csv', 'percent', 'No'],\n",
        "    ['desert_q_def1', 'Desert (quartile): high Medi-Cal & low PCP', 'Derived', 'binary', 'Yes'],\n",
        "    ['desert_q_def2', 'Desert (quartile): high Medi-Cal & (low PCP OR shortage)', 'Derived', 'binary', 'Yes'],\n",
        "    ['desert_thr_def1', 'Desert (threshold): high Medi-Cal & low PCP', 'Derived', 'binary', 'Yes'],\n",
        "    ['desert_thr_def2', 'Desert (threshold): high Medi-Cal & (low PCP OR shortage)', 'Derived', 'binary', 'Yes'],\n",
        "], columns=['Variable', 'Description', 'Source File', 'Unit', 'Time-Varying'])\n",
        "\n",
        "var_dict.to_csv('outputs/data/ca_variable_dictionary.csv', index=False)\n",
        "print(\"✓ Saved: outputs/data/ca_variable_dictionary.csv\")\n",
        "print(\"\\nVariable dictionary:\")\n",
        "print(var_dict.to_string())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10) Descriptive Figures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set matplotlib style\n",
        "plt.style.use('default')\n",
        "fig_dpi = 300\n",
        "\n",
        "# 1. Histogram of medi_cal_share with threshold\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "ax.hist(master_panel['medi_cal_share'].dropna(), bins=50, edgecolor='black', alpha=0.7)\n",
        "ax.axvline(medi_cal_threshold, color='red', linestyle='--', linewidth=2, label=f'Threshold: {medi_cal_threshold}')\n",
        "ax.set_xlabel('Medi-Cal Share', fontsize=12)\n",
        "ax.set_ylabel('Frequency', fontsize=12)\n",
        "ax.set_title('Distribution of Medi-Cal Share Across County-Years', fontsize=14, fontweight='bold')\n",
        "ax.legend()\n",
        "ax.grid(alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig('outputs/figures/hist_medi_cal_share.png', dpi=fig_dpi, bbox_inches='tight')\n",
        "print(\"✓ Saved: outputs/figures/hist_medi_cal_share.png\")\n",
        "plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2. Histogram of pcp_per_100k\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "ax.hist(master_panel['pcp_per_100k'].dropna(), bins=50, edgecolor='black', alpha=0.7)\n",
        "ax.axvline(pcp_threshold, color='red', linestyle='--', linewidth=2, label=f'Threshold: {pcp_threshold:.2f}')\n",
        "ax.set_xlabel('Primary Care Physicians per 100,000', fontsize=12)\n",
        "ax.set_ylabel('Frequency', fontsize=12)\n",
        "ax.set_title('Distribution of Primary Care Physician Supply (per 100k)', fontsize=14, fontweight='bold')\n",
        "ax.legend()\n",
        "ax.grid(alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig('outputs/figures/hist_pcp_per_100k.png', dpi=fig_dpi, bbox_inches='tight')\n",
        "print(\"✓ Saved: outputs/figures/hist_pcp_per_100k.png\")\n",
        "plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3. Time series: statewide (population-weighted) medi_cal_share and pqi_mean_rate\n",
        "statewide = master_panel.groupby('year').apply(\n",
        "    lambda x: pd.Series({\n",
        "        'medi_cal_share_weighted': np.average(x['medi_cal_share'], weights=x['population']),\n",
        "        'pqi_mean_rate_weighted': np.average(x['pqi_mean_rate'], weights=x['population'])\n",
        "    })\n",
        ").reset_index()\n",
        "\n",
        "fig, ax1 = plt.subplots(figsize=(12, 6))\n",
        "ax2 = ax1.twinx()\n",
        "\n",
        "line1 = ax1.plot(statewide['year'], statewide['medi_cal_share_weighted'], \n",
        "                'b-', linewidth=2, marker='o', label='Medi-Cal Share')\n",
        "ax1.set_xlabel('Year', fontsize=12)\n",
        "ax1.set_ylabel('Medi-Cal Share (Population-Weighted)', fontsize=12, color='b')\n",
        "ax1.tick_params(axis='y', labelcolor='b')\n",
        "ax1.grid(alpha=0.3)\n",
        "\n",
        "line2 = ax2.plot(statewide['year'], statewide['pqi_mean_rate_weighted'], \n",
        "                'r-', linewidth=2, marker='s', label='PQI Mean Rate')\n",
        "ax2.set_ylabel('PQI Mean Rate (Population-Weighted)', fontsize=12, color='r')\n",
        "ax2.tick_params(axis='y', labelcolor='r')\n",
        "\n",
        "ax1.set_title('Statewide Trends: Medi-Cal Share and PQI Rates', fontsize=14, fontweight='bold')\n",
        "fig.legend(loc='upper left', bbox_to_anchor=(0.1, 0.9))\n",
        "plt.tight_layout()\n",
        "plt.savefig('outputs/figures/time_series_statewide.png', dpi=fig_dpi, bbox_inches='tight')\n",
        "print(\"✓ Saved: outputs/figures/time_series_statewide.png\")\n",
        "plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4. Scatter: medi_cal_share vs pcp_per_100k (label top 5 outliers)\n",
        "fig, ax = plt.subplots(figsize=(10, 8))\n",
        "ax.scatter(master_panel['medi_cal_share'], master_panel['pcp_per_100k'], \n",
        "          alpha=0.5, s=30, edgecolors='black', linewidth=0.5)\n",
        "\n",
        "# Identify top 5 outliers (by distance from center)\n",
        "center_x = master_panel['medi_cal_share'].median()\n",
        "center_y = master_panel['pcp_per_100k'].median()\n",
        "master_panel['dist_from_center'] = np.sqrt(\n",
        "    ((master_panel['medi_cal_share'] - center_x) ** 2) + \n",
        "    ((master_panel['pcp_per_100k'] - center_y) ** 2)\n",
        ")\n",
        "top_outliers = master_panel.nlargest(5, 'dist_from_center')\n",
        "\n",
        "# Label outliers\n",
        "for idx, row in top_outliers.iterrows():\n",
        "    county_name = crosswalk_clean[crosswalk_clean['fips5'] == row['fips5']]['county_name_clean'].values\n",
        "    if len(county_name) > 0:\n",
        "        ax.annotate(county_name[0], (row['medi_cal_share'], row['pcp_per_100k']), \n",
        "                   fontsize=8, alpha=0.7)\n",
        "\n",
        "ax.set_xlabel('Medi-Cal Share', fontsize=12)\n",
        "ax.set_ylabel('Primary Care Physicians per 100,000', fontsize=12)\n",
        "ax.set_title('Medi-Cal Share vs Primary Care Supply', fontsize=14, fontweight='bold')\n",
        "ax.grid(alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig('outputs/figures/scatter_medi_cal_vs_pcp.png', dpi=fig_dpi, bbox_inches='tight')\n",
        "print(\"✓ Saved: outputs/figures/scatter_medi_cal_vs_pcp.png\")\n",
        "plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 5. Scatter: pcp_per_100k vs pqi_mean_rate (with fitted line)\n",
        "fig, ax = plt.subplots(figsize=(10, 8))\n",
        "ax.scatter(master_panel['pcp_per_100k'], master_panel['pqi_mean_rate'], \n",
        "          alpha=0.5, s=30, edgecolors='black', linewidth=0.5)\n",
        "\n",
        "# Fit line\n",
        "mask = master_panel[['pcp_per_100k', 'pqi_mean_rate']].notna().all(axis=1)\n",
        "if mask.sum() > 0:\n",
        "    x_fit = master_panel.loc[mask, 'pcp_per_100k']\n",
        "    y_fit = master_panel.loc[mask, 'pqi_mean_rate']\n",
        "    z = np.polyfit(x_fit, y_fit, 1)\n",
        "    p = np.poly1d(z)\n",
        "    ax.plot(x_fit, p(x_fit), \"r--\", alpha=0.8, linewidth=2, label=f'Fitted line: y={z[0]:.2f}x+{z[1]:.2f}')\n",
        "    ax.legend()\n",
        "\n",
        "ax.set_xlabel('Primary Care Physicians per 100,000', fontsize=12)\n",
        "ax.set_ylabel('PQI Mean Rate', fontsize=12)\n",
        "ax.set_title('Primary Care Supply vs Preventable Hospitalizations', fontsize=14, fontweight='bold')\n",
        "ax.grid(alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig('outputs/figures/scatter_pcp_vs_pqi.png', dpi=fig_dpi, bbox_inches='tight')\n",
        "print(\"✓ Saved: outputs/figures/scatter_pcp_vs_pqi.png\")\n",
        "plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 6. Bar: top/bottom 10 counties in pqi_mean_rate for latest year\n",
        "latest_year = master_panel['year'].max()\n",
        "latest_data = master_panel[master_panel['year'] == latest_year].copy()\n",
        "latest_data = latest_data.merge(crosswalk_clean[['fips5', 'county_name_clean']], on='fips5', how='left')\n",
        "\n",
        "top10 = latest_data.nlargest(10, 'pqi_mean_rate')\n",
        "bottom10 = latest_data.nsmallest(10, 'pqi_mean_rate')\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# Top 10\n",
        "ax1.barh(range(len(top10)), top10['pqi_mean_rate'], color='coral', edgecolor='black')\n",
        "ax1.set_yticks(range(len(top10)))\n",
        "ax1.set_yticklabels(top10['county_name_clean'], fontsize=9)\n",
        "ax1.set_xlabel('PQI Mean Rate', fontsize=12)\n",
        "ax1.set_title(f'Top 10 Counties: Highest PQI Rates ({latest_year:.0f})', fontsize=12, fontweight='bold')\n",
        "ax1.grid(axis='x', alpha=0.3)\n",
        "ax1.invert_yaxis()\n",
        "\n",
        "# Bottom 10\n",
        "ax2.barh(range(len(bottom10)), bottom10['pqi_mean_rate'], color='lightblue', edgecolor='black')\n",
        "ax2.set_yticks(range(len(bottom10)))\n",
        "ax2.set_yticklabels(bottom10['county_name_clean'], fontsize=9)\n",
        "ax2.set_xlabel('PQI Mean Rate', fontsize=12)\n",
        "ax2.set_title(f'Bottom 10 Counties: Lowest PQI Rates ({latest_year:.0f})', fontsize=12, fontweight='bold')\n",
        "ax2.grid(axis='x', alpha=0.3)\n",
        "ax2.invert_yaxis()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('outputs/figures/bar_top_bottom_pqi.png', dpi=fig_dpi, bbox_inches='tight')\n",
        "print(\"✓ Saved: outputs/figures/bar_top_bottom_pqi.png\")\n",
        "plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optional maps (only if shapefile exists)\n",
        "# Check for common shapefile names\n",
        "shapefile_candidates = [\n",
        "    'ca_counties.shp', 'california_counties.shp', 'CA_Counties.shp',\n",
        "    'counties.shp', 'ca_county_boundaries.shp'\n",
        "]\n",
        "\n",
        "shapefile_path = None\n",
        "for candidate in shapefile_candidates:\n",
        "    if os.path.exists(candidate):\n",
        "        shapefile_path = candidate\n",
        "        break\n",
        "\n",
        "if shapefile_path and HAS_GEOPANDAS:\n",
        "    print(f\"Found shapefile: {shapefile_path}\")\n",
        "    try:\n",
        "        gdf = gpd.read_file(shapefile_path)\n",
        "        # Ensure FIPS column exists and matches\n",
        "        if 'FIPS' in gdf.columns or 'GEOID' in gdf.columns:\n",
        "            fips_col = 'FIPS' if 'FIPS' in gdf.columns else 'GEOID'\n",
        "            gdf['fips5'] = gdf[fips_col].astype(str).str.zfill(5)\n",
        "            \n",
        "            # Choose a year for mapping\n",
        "            map_year = master_panel['year'].median()\n",
        "            map_data = master_panel[master_panel['year'] == map_year].copy()\n",
        "            \n",
        "            # Merge\n",
        "            gdf_map = gdf.merge(map_data, on='fips5', how='left')\n",
        "            \n",
        "            # Create maps\n",
        "            fig, axes = plt.subplots(2, 2, figsize=(16, 16))\n",
        "            axes = axes.flatten()\n",
        "            \n",
        "            vars_to_map = ['medi_cal_share', 'pcp_per_100k', 'pqi_mean_rate', 'desert_q_def2']\n",
        "            titles = ['Medi-Cal Share', 'PCP per 100k', 'PQI Mean Rate', 'Desert (Quartile Def2)']\n",
        "            \n",
        "            for ax, var, title in zip(axes, vars_to_map, titles):\n",
        "                if var in gdf_map.columns:\n",
        "                    gdf_map.plot(column=var, ax=ax, legend=True, cmap='YlOrRd', \n",
        "                               missing_kwds={'color': 'lightgrey'}, edgecolor='black', linewidth=0.5)\n",
        "                    ax.set_title(f'{title} ({map_year:.0f})', fontsize=12, fontweight='bold')\n",
        "                    ax.axis('off')\n",
        "            \n",
        "            plt.tight_layout()\n",
        "            plt.savefig('outputs/figures/maps_california.png', dpi=fig_dpi, bbox_inches='tight')\n",
        "            print(\"✓ Saved: outputs/figures/maps_california.png\")\n",
        "            plt.close()\n",
        "    except Exception as e:\n",
        "        print(f\"⚠ Could not create maps: {e}\")\n",
        "else:\n",
        "    print(\"⚠ No shapefile found or geopandas not available. Skipping maps.\")\n",
        "    print(\"  (This is expected - maps are optional per requirements)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11) Regression Analyses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare data for regression\n",
        "reg_data = master_panel.copy()\n",
        "\n",
        "# Drop rows with missing key variables\n",
        "key_vars = ['pqi_mean_rate', 'medi_cal_share', 'pcp_per_100k', 'shortage_flag',\n",
        "           'poverty_pct', 'unemp_pct', 'age65_pct', 'hispanic_pct', 'bachelors_pct']\n",
        "reg_data = reg_data.dropna(subset=key_vars)\n",
        "\n",
        "print(f\"Regression sample: {len(reg_data)} county-years\")\n",
        "print(f\"Unique counties: {reg_data['fips5'].nunique()}\")\n",
        "print(f\"Year range: {reg_data['year'].min():.0f} - {reg_data['year'].max():.0f}\")\n",
        "\n",
        "# Set index for PanelOLS if using\n",
        "if HAS_PANELOLS:\n",
        "    reg_data_indexed = reg_data.set_index(['fips5', 'year']).sort_index()\n",
        "else:\n",
        "    reg_data_indexed = reg_data.copy()\n",
        "\n",
        "# Prepare controls\n",
        "controls = ['poverty_pct', 'unemp_pct', 'age65_pct', 'hispanic_pct', 'bachelors_pct']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# MODEL A: Provider Supply Model\n",
        "print(\"=\" * 60)\n",
        "print(\"MODEL A: Provider Supply Model\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "if IS_TIME_VARYING:\n",
        "    print(\"PCP supply is time-varying. Using panel model.\")\n",
        "    Y1 = reg_data_indexed['pcp_per_100k']\n",
        "    X1 = reg_data_indexed[['medi_cal_share', 'shortage_flag'] + controls]\n",
        "    \n",
        "    if HAS_PANELOLS:\n",
        "        model_a = PanelOLS(Y1, X1, entity_effects=True, time_effects=True)\n",
        "        results_a = model_a.fit(cov_type='clustered', cluster_entity=True)\n",
        "    else:\n",
        "        # Use statsmodels with dummies\n",
        "        X1_with_dummies = X1.copy()\n",
        "        X1_with_dummies = pd.get_dummies(X1_with_dummies, columns=['fips5'], prefix='county', drop_first=False)\n",
        "        X1_with_dummies = pd.get_dummies(X1_with_dummies, columns=['year'], prefix='year', drop_first=False)\n",
        "        X1_with_dummies = sm.add_constant(X1_with_dummies)\n",
        "        model_a = OLS(Y1, X1_with_dummies)\n",
        "        results_a = model_a.fit(cov_type='cluster', cov_kwds={'groups': reg_data_indexed.index.get_level_values(0)})\n",
        "else:\n",
        "    print(\"PCP supply is time-invariant. Using cross-sectional model.\")\n",
        "    # Aggregate to county level\n",
        "    reg_data_cs = reg_data.groupby('fips5').agg({\n",
        "        'pcp_per_100k': 'first',\n",
        "        'medi_cal_share': 'mean',\n",
        "        'shortage_flag': 'first',\n",
        "        'poverty_pct': 'first',\n",
        "        'unemp_pct': 'first',\n",
        "        'age65_pct': 'first',\n",
        "        'hispanic_pct': 'first',\n",
        "        'bachelors_pct': 'first'\n",
        "    }).reset_index()\n",
        "    \n",
        "    Y1 = reg_data_cs['pcp_per_100k']\n",
        "    X1 = reg_data_cs[['medi_cal_share', 'shortage_flag'] + controls]\n",
        "    X1 = sm.add_constant(X1)\n",
        "    \n",
        "    model_a = OLS(Y1, X1)\n",
        "    results_a = model_a.fit()\n",
        "\n",
        "print(results_a.summary())\n",
        "\n",
        "# Save results\n",
        "results_a_df = pd.DataFrame({\n",
        "    'Variable': results_a.params.index,\n",
        "    'Coefficient': results_a.params.values,\n",
        "    'Std_Error': results_a.std_errors.values if hasattr(results_a, 'std_errors') else results_a.bse.values,\n",
        "    'P_Value': results_a.pvalues.values,\n",
        "    'CI_Lower': results_a.conf_int()[0].values,\n",
        "    'CI_Upper': results_a.conf_int()[1].values\n",
        "})\n",
        "results_a_df.to_csv('outputs/tables/reg_model_a_supply.csv', index=False)\n",
        "print(\"\\n✓ Saved: outputs/tables/reg_model_a_supply.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# MODEL B: Outcomes Model\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"MODEL B: Outcomes Model\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "X2_vars = ['pcp_per_100k', 'medi_cal_share', 'shortage_flag'] + controls\n",
        "\n",
        "if HAS_PANELOLS:\n",
        "    Y2 = reg_data_indexed['pqi_mean_rate']\n",
        "    X2 = reg_data_indexed[X2_vars]\n",
        "    model_b = PanelOLS(Y2, X2, entity_effects=True, time_effects=True)\n",
        "    results_b = model_b.fit(cov_type='clustered', cluster_entity=True)\n",
        "else:\n",
        "    # Use simple OLS with controls (no fixed effects since data is limited)\n",
        "    Y2 = reg_data['pqi_mean_rate']\n",
        "    X2 = reg_data[X2_vars].copy()\n",
        "    X2 = sm.add_constant(X2)\n",
        "    model_b = OLS(Y2, X2)\n",
        "    results_b = model_b.fit()\n",
        "\n",
        "print(results_b.summary())\n",
        "\n",
        "# Save results\n",
        "results_b_df = pd.DataFrame({\n",
        "    'Variable': results_b.params.index,\n",
        "    'Coefficient': results_b.params.values,\n",
        "    'Std_Error': results_b.std_errors.values if hasattr(results_b, 'std_errors') else results_b.bse.values,\n",
        "    'P_Value': results_b.pvalues.values,\n",
        "    'CI_Lower': results_b.conf_int()[0].values,\n",
        "    'CI_Upper': results_b.conf_int()[1].values\n",
        "})\n",
        "results_b_df.to_csv('outputs/tables/reg_model_b_outcomes.csv', index=False)\n",
        "print(\"\\n✓ Saved: outputs/tables/reg_model_b_outcomes.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# MODEL C: Desert Indicator Model\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"MODEL C: Desert Indicator Model\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "X3_vars = ['desert_q_def2'] + controls\n",
        "\n",
        "if HAS_PANELOLS:\n",
        "    Y3 = reg_data_indexed['pqi_mean_rate']\n",
        "    X3 = reg_data_indexed[X3_vars]\n",
        "    model_c = PanelOLS(Y3, X3, entity_effects=True, time_effects=True)\n",
        "    results_c = model_c.fit(cov_type='clustered', cluster_entity=True)\n",
        "else:\n",
        "    # Use simple OLS with controls\n",
        "    Y3 = reg_data['pqi_mean_rate']\n",
        "    X3 = reg_data[X3_vars].copy()\n",
        "    X3 = sm.add_constant(X3)\n",
        "    model_c = OLS(Y3, X3)\n",
        "    results_c = model_c.fit()\n",
        "\n",
        "print(results_c.summary())\n",
        "\n",
        "# Save results\n",
        "results_c_df = pd.DataFrame({\n",
        "    'Variable': results_c.params.index,\n",
        "    'Coefficient': results_c.params.values,\n",
        "    'Std_Error': results_c.std_errors.values if hasattr(results_c, 'std_errors') else results_c.bse.values,\n",
        "    'P_Value': results_c.pvalues.values,\n",
        "    'CI_Lower': results_c.conf_int()[0].values,\n",
        "    'CI_Upper': results_c.conf_int()[1].values\n",
        "})\n",
        "results_c_df.to_csv('outputs/tables/reg_model_c_desert.csv', index=False)\n",
        "print(\"\\n✓ Saved: outputs/tables/reg_model_c_desert.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create regression summary markdown\n",
        "# Extract values first\n",
        "medi_cal_coef_a = results_a.params.get('medi_cal_share', np.nan)\n",
        "shortage_coef_a = results_a.params.get('shortage_flag', np.nan)\n",
        "pcp_coef_b = results_b.params.get('pcp_per_100k', np.nan)\n",
        "medi_cal_coef_b = results_b.params.get('medi_cal_share', np.nan)\n",
        "shortage_coef_b = results_b.params.get('shortage_flag', np.nan)\n",
        "desert_coef_c = results_c.params.get('desert_q_def2', np.nan)\n",
        "n_obs = len(reg_data_indexed) if HAS_PANELOLS else len(reg_data)\n",
        "n_counties = reg_data['fips5'].nunique()\n",
        "\n",
        "summary_md = f\"\"\"# Regression Results Summary\n",
        "\n",
        "## Model A: Provider Supply Model\n",
        "**Dependent Variable:** pcp_per_100k (Primary care physicians per 100,000)\n",
        "\n",
        "**Key Findings:**\n",
        "- Medi-Cal Share coefficient: {medi_cal_coef_a:.4f}\n",
        "- Shortage Flag coefficient: {shortage_coef_a:.4f}\n",
        "- N observations: {n_obs}\n",
        "- N counties: {n_counties}\n",
        "\n",
        "## Model B: Outcomes Model\n",
        "**Dependent Variable:** pqi_mean_rate (Mean PQI rate)\n",
        "\n",
        "**Key Findings:**\n",
        "- PCP per 100k coefficient: {pcp_coef_b:.4f}\n",
        "- Medi-Cal Share coefficient: {medi_cal_coef_b:.4f}\n",
        "- Shortage Flag coefficient: {shortage_coef_b:.4f}\n",
        "- N observations: {n_obs}\n",
        "- N counties: {n_counties}\n",
        "\n",
        "## Model C: Desert Indicator Model\n",
        "**Dependent Variable:** pqi_mean_rate (Mean PQI rate)\n",
        "\n",
        "**Key Findings:**\n",
        "- Desert (Quartile Def2) coefficient: {desert_coef_c:.4f}\n",
        "- N observations: {n_obs}\n",
        "- N counties: {n_counties}\n",
        "\n",
        "## Interpretation\n",
        "\n",
        "### Model A Interpretation:\n",
        "A +0.10 increase in medi_cal_share is associated with Δ {medi_cal_coef_a * 0.10:.2f} pcp_per_100k.\n",
        "\n",
        "### Model B Interpretation:\n",
        "An increase of +10 pcp_per_100k is associated with Δ {pcp_coef_b * 10:.2f} pqi_mean_rate.\n",
        "\n",
        "**Note:** Standard errors are clustered at the county level.\n",
        "\"\"\"\n",
        "\n",
        "with open('outputs/tables/regression_summary.md', 'w') as f:\n",
        "    f.write(summary_md)\n",
        "\n",
        "print(\"✓ Saved: outputs/tables/regression_summary.md\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12) Robustness / Sensitivity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sensitivity checks\n",
        "sensitivity_results = []\n",
        "\n",
        "# 1. Alternative desert definitions\n",
        "print(\"Running sensitivity checks...\")\n",
        "\n",
        "# Model B with alternative definitions\n",
        "for desert_var in ['desert_q_def1', 'desert_thr_def1', 'desert_thr_def2']:\n",
        "    if desert_var in reg_data.columns and reg_data[desert_var].sum() > 0:\n",
        "        Y_sens = reg_data['pqi_mean_rate']\n",
        "        X_sens_vars = [desert_var] + controls\n",
        "        X_sens = reg_data[X_sens_vars].copy()\n",
        "        \n",
        "        if HAS_PANELOLS:\n",
        "            Y_sens_idx = reg_data_indexed['pqi_mean_rate']\n",
        "            X_sens_idx = reg_data_indexed[X_sens_vars]\n",
        "            model_sens = PanelOLS(Y_sens_idx, X_sens_idx, entity_effects=True, time_effects=True)\n",
        "            results_sens = model_sens.fit(cov_type='clustered', cluster_entity=True)\n",
        "        else:\n",
        "            # Simple OLS without fixed effects\n",
        "            X_sens = sm.add_constant(X_sens)\n",
        "            model_sens = OLS(Y_sens, X_sens)\n",
        "            results_sens = model_sens.fit()\n",
        "        \n",
        "        coef = results_sens.params.get(desert_var, np.nan)\n",
        "        se = results_sens.std_errors.get(desert_var, np.nan) if hasattr(results_sens, 'std_errors') else results_sens.bse.get(desert_var, np.nan)\n",
        "        pval = results_sens.pvalues.get(desert_var, np.nan)\n",
        "        \n",
        "        sensitivity_results.append({\n",
        "            'Specification': f'Model B - {desert_var}',\n",
        "            'Coefficient': coef,\n",
        "            'Std_Error': se,\n",
        "            'P_Value': pval\n",
        "        })\n",
        "        print(f\"  {desert_var}: coef={coef:.4f}, se={se:.4f}, p={pval:.4f}\")\n",
        "    else:\n",
        "        print(f\"  Skipping {desert_var} - no variation in data\")\n",
        "\n",
        "# 2. Winsorize outliers\n",
        "print(\"\\n  Running winsorized model...\")\n",
        "reg_data_winsor = reg_data.copy()\n",
        "reg_data_winsor['medi_cal_share_w'] = reg_data_winsor['medi_cal_share'].clip(\n",
        "    lower=reg_data_winsor['medi_cal_share'].quantile(0.01),\n",
        "    upper=reg_data_winsor['medi_cal_share'].quantile(0.99)\n",
        ")\n",
        "reg_data_winsor['pqi_mean_rate_w'] = reg_data_winsor['pqi_mean_rate'].clip(\n",
        "    lower=reg_data_winsor['pqi_mean_rate'].quantile(0.01),\n",
        "    upper=reg_data_winsor['pqi_mean_rate'].quantile(0.99)\n",
        ")\n",
        "\n",
        "Y_w = reg_data_winsor['pqi_mean_rate_w']\n",
        "X_w_vars = ['pcp_per_100k', 'medi_cal_share_w', 'shortage_flag'] + controls\n",
        "X_w = reg_data_winsor[X_w_vars].copy()\n",
        "\n",
        "if HAS_PANELOLS:\n",
        "    reg_data_winsor_indexed = reg_data_winsor.set_index(['fips5', 'year']).sort_index()\n",
        "    Y_w = reg_data_winsor_indexed['pqi_mean_rate_w']\n",
        "    X_w = reg_data_winsor_indexed[X_w_vars]\n",
        "    model_w = PanelOLS(Y_w, X_w, entity_effects=True, time_effects=True)\n",
        "    results_w = model_w.fit(cov_type='clustered', cluster_entity=True)\n",
        "else:\n",
        "    # Simple OLS without fixed effects\n",
        "    X_w = sm.add_constant(X_w)\n",
        "    model_w = OLS(Y_w, X_w)\n",
        "    results_w = model_w.fit()\n",
        "\n",
        "sensitivity_results.append({\n",
        "    'Specification': 'Model B - Winsorized (1st/99th percentile)',\n",
        "    'Coefficient': results_w.params.get('pcp_per_100k', np.nan),\n",
        "    'Std_Error': results_w.std_errors.get('pcp_per_100k', np.nan) if hasattr(results_w, 'std_errors') else results_w.bse.get('pcp_per_100k', np.nan),\n",
        "    'P_Value': results_w.pvalues.get('pcp_per_100k', np.nan)\n",
        "})\n",
        "print(f\"  Winsorized: coef={results_w.params.get('pcp_per_100k', np.nan):.4f}\")\n",
        "\n",
        "# Save sensitivity results\n",
        "sensitivity_df = pd.DataFrame(sensitivity_results)\n",
        "sensitivity_df.to_csv('outputs/tables/sensitivity_checks.csv', index=False)\n",
        "print(\"\\n✓ Saved: outputs/tables/sensitivity_checks.csv\")\n",
        "print(\"\\nSensitivity Results:\")\n",
        "print(sensitivity_df.to_string())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 13) Appendix Diagnostics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Missingness table\n",
        "missingness_table = summarize_missingness(master_panel, \"Master Panel\")\n",
        "missingness_table.to_csv('outputs/tables/missingness_table.csv')\n",
        "print(\"\\n✓ Saved: outputs/tables/missingness_table.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Correlation matrix of main variables\n",
        "main_vars = ['medi_cal_share', 'pcp_per_100k', 'pqi_mean_rate', 'shortage_flag',\n",
        "            'poverty_pct', 'unemp_pct', 'age65_pct', 'hispanic_pct', 'bachelors_pct']\n",
        "corr_data = master_panel[main_vars].dropna()\n",
        "corr_matrix = corr_data.corr()\n",
        "\n",
        "corr_matrix.to_csv('outputs/tables/correlation_matrix.csv')\n",
        "print(\"✓ Saved: outputs/tables/correlation_matrix.csv\")\n",
        "print(\"\\nCorrelation Matrix (main variables):\")\n",
        "print(corr_matrix.round(3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# County coverage table by year\n",
        "coverage_by_year = master_panel.groupby('year').agg({\n",
        "    'fips5': 'nunique',\n",
        "    'medi_cal_share': 'count',\n",
        "    'pcp_per_100k': 'count',\n",
        "    'pqi_mean_rate': 'count'\n",
        "}).reset_index()\n",
        "coverage_by_year.columns = ['Year', 'N_Counties', 'N_MediCal', 'N_PCP', 'N_PQI']\n",
        "\n",
        "coverage_by_year.to_csv('outputs/tables/county_coverage_by_year.csv', index=False)\n",
        "print(\"✓ Saved: outputs/tables/county_coverage_by_year.csv\")\n",
        "print(\"\\nCounty Coverage by Year:\")\n",
        "print(coverage_by_year.to_string())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create results summary\n",
        "# Extract values first to avoid f-string syntax issues\n",
        "medi_cal_share_coef_a = results_a.params.get('medi_cal_share', np.nan)\n",
        "medi_cal_share_se_a = results_a.std_errors.get('medi_cal_share', np.nan) if hasattr(results_a, 'std_errors') else results_a.bse.get('medi_cal_share', np.nan)\n",
        "shortage_flag_coef_a = results_a.params.get('shortage_flag', np.nan)\n",
        "shortage_flag_se_a = results_a.std_errors.get('shortage_flag', np.nan) if hasattr(results_a, 'std_errors') else results_a.bse.get('shortage_flag', np.nan)\n",
        "\n",
        "pcp_coef_b = results_b.params.get('pcp_per_100k', np.nan)\n",
        "pcp_se_b = results_b.std_errors.get('pcp_per_100k', np.nan) if hasattr(results_b, 'std_errors') else results_b.bse.get('pcp_per_100k', np.nan)\n",
        "medi_cal_share_coef_b = results_b.params.get('medi_cal_share', np.nan)\n",
        "medi_cal_share_se_b = results_b.std_errors.get('medi_cal_share', np.nan) if hasattr(results_b, 'std_errors') else results_b.bse.get('medi_cal_share', np.nan)\n",
        "shortage_flag_coef_b = results_b.params.get('shortage_flag', np.nan)\n",
        "shortage_flag_se_b = results_b.std_errors.get('shortage_flag', np.nan) if hasattr(results_b, 'std_errors') else results_b.bse.get('shortage_flag', np.nan)\n",
        "\n",
        "desert_coef_c = results_c.params.get('desert_q_def2', np.nan)\n",
        "desert_se_c = results_c.std_errors.get('desert_q_def2', np.nan) if hasattr(results_c, 'std_errors') else results_c.bse.get('desert_q_def2', np.nan)\n",
        "\n",
        "physician_supply_text = 'Physician supply is time-invariant' if not IS_TIME_VARYING else 'Physician supply varies by year'\n",
        "physician_supply_note = 'This limits the ability to examine within-county changes over time.' if not IS_TIME_VARYING else ''\n",
        "shortage_text = 'Shortage designation is time-invariant' if not IS_SHORTAGE_TIME_VARYING else 'Shortage designation varies by year'\n",
        "\n",
        "results_summary = f\"\"\"# California Medi-Cal Deserts Capstone Project - Results Summary\n",
        "\n",
        "## Data Sources\n",
        "- County crosswalk: county name.xlsx\n",
        "- Medi-Cal enrollment: medi-cal-enrollment-dashboard-data.csv\n",
        "- Population: E4 estiamtes.xlsx\n",
        "- Physician supply: physicians-actively-working-by-specialty-and-patient-care-hours.xlsx\n",
        "- Shortage designation: Primary CAre Shortage .csv\n",
        "- PQI outcomes: PQI.csv\n",
        "- ACS controls: demoACS.csv, educACS.csv, EconACS.csv\n",
        "\n",
        "## Final Dataset\n",
        "- **Year range:** {master_panel['year'].min():.0f} - {master_panel['year'].max():.0f}\n",
        "- **N counties:** {master_panel['fips5'].nunique()}\n",
        "- **N county-years:** {len(master_panel)}\n",
        "- **Desert definition (main results):** Quartile-based Definition 2 (high Medi-Cal & (low PCP OR shortage))\n",
        "\n",
        "## Key Descriptive Findings\n",
        "\n",
        "### Medi-Cal Intensity\n",
        "- Mean Medi-Cal share: {master_panel['medi_cal_share'].mean():.3f}\n",
        "- Median Medi-Cal share: {master_panel['medi_cal_share'].median():.3f}\n",
        "- Range: {master_panel['medi_cal_share'].min():.3f} - {master_panel['medi_cal_share'].max():.3f}\n",
        "\n",
        "### Primary Care Supply\n",
        "- Mean PCP per 100k: {master_panel['pcp_per_100k'].mean():.2f}\n",
        "- Median PCP per 100k: {master_panel['pcp_per_100k'].median():.2f}\n",
        "- Range: {master_panel['pcp_per_100k'].min():.2f} - {master_panel['pcp_per_100k'].max():.2f}\n",
        "- **Time-varying:** {'Yes' if IS_TIME_VARYING else 'No (time-invariant)'}\n",
        "\n",
        "### Preventable Hospitalizations (PQI)\n",
        "- Mean PQI rate: {master_panel['pqi_mean_rate'].mean():.2f}\n",
        "- Median PQI rate: {master_panel['pqi_mean_rate'].median():.2f}\n",
        "- Range: {master_panel['pqi_mean_rate'].min():.2f} - {master_panel['pqi_mean_rate'].max():.2f}\n",
        "\n",
        "### Shortage Designations\n",
        "- Counties with shortage designation: {(master_panel['shortage_flag'] == 1).sum()} county-years\n",
        "- **Time-varying:** {'Yes' if IS_SHORTAGE_TIME_VARYING else 'No (time-invariant)'}\n",
        "\n",
        "### Desert Classifications\n",
        "- Desert (Quartile Def1): {master_panel['desert_q_def1'].sum()} county-years\n",
        "- Desert (Quartile Def2): {master_panel['desert_q_def2'].sum()} county-years\n",
        "- Desert (Threshold Def1): {master_panel['desert_thr_def1'].sum()} county-years\n",
        "- Desert (Threshold Def2): {master_panel['desert_thr_def2'].sum()} county-years\n",
        "\n",
        "## Key Regression Findings (with Clustered Standard Errors)\n",
        "\n",
        "### Model A: Provider Supply Model\n",
        "**Dependent Variable:** pcp_per_100k\n",
        "\n",
        "- **Medi-Cal Share:** {medi_cal_share_coef_a:.4f} (SE: {medi_cal_share_se_a:.4f})\n",
        "- **Shortage Flag:** {shortage_flag_coef_a:.4f} (SE: {shortage_flag_se_a:.4f})\n",
        "\n",
        "**Interpretation:** A +0.10 increase in medi_cal_share is associated with Δ {medi_cal_share_coef_a * 0.10:.2f} pcp_per_100k.\n",
        "\n",
        "### Model B: Outcomes Model\n",
        "**Dependent Variable:** pqi_mean_rate\n",
        "\n",
        "- **PCP per 100k:** {pcp_coef_b:.4f} (SE: {pcp_se_b:.4f})\n",
        "- **Medi-Cal Share:** {medi_cal_share_coef_b:.4f} (SE: {medi_cal_share_se_b:.4f})\n",
        "- **Shortage Flag:** {shortage_flag_coef_b:.4f} (SE: {shortage_flag_se_b:.4f})\n",
        "\n",
        "**Interpretation:** An increase of +10 pcp_per_100k is associated with Δ {pcp_coef_b * 10:.2f} pqi_mean_rate.\n",
        "\n",
        "### Model C: Desert Indicator Model\n",
        "**Dependent Variable:** pqi_mean_rate\n",
        "\n",
        "- **Desert (Quartile Def2):** {desert_coef_c:.4f} (SE: {desert_se_c:.4f})\n",
        "\n",
        "## Limitations\n",
        "\n",
        "1. **ACS Controls:** ACS controls are likely single-year (baseline) and treated as time-invariant. This may not capture time-varying demographic/economic changes.\n",
        "\n",
        "2. **Physician Supply:** {physician_supply_text}. {physician_supply_note}\n",
        "\n",
        "3. **Shortage Designation:** {shortage_text}.\n",
        "\n",
        "4. **Ecological Inference:** Results are at the county-year level. Individual-level relationships may differ.\n",
        "\n",
        "5. **Causality:** These are observational associations. Causal interpretation requires additional assumptions and methods.\n",
        "\n",
        "## Output Files Generated\n",
        "\n",
        "### Data Files (outputs/data/)\n",
        "- county_crosswalk_clean.csv\n",
        "- pop_e4_clean.csv\n",
        "- medical_enrollment_clean.csv\n",
        "- physician_supply_clean.csv\n",
        "- shortage_clean.csv\n",
        "- acs_controls_clean.csv\n",
        "- pqi_long_clean.csv\n",
        "- pqi_county_year_clean.csv\n",
        "- ca_master_panel.csv\n",
        "- ca_variable_dictionary.csv\n",
        "\n",
        "### Figures (outputs/figures/)\n",
        "- hist_medi_cal_share.png\n",
        "- hist_pcp_per_100k.png\n",
        "- time_series_statewide.png\n",
        "- scatter_medi_cal_vs_pcp.png\n",
        "- scatter_pcp_vs_pqi.png\n",
        "- bar_top_bottom_pqi.png\n",
        "- maps_california.png (if shapefile available)\n",
        "\n",
        "### Tables (outputs/tables/)\n",
        "- primary_care_specialty_definition.csv\n",
        "- reg_model_a_supply.csv\n",
        "- reg_model_b_outcomes.csv\n",
        "- reg_model_c_desert.csv\n",
        "- regression_summary.md\n",
        "- sensitivity_checks.csv\n",
        "- missingness_table.csv\n",
        "- correlation_matrix.csv\n",
        "- county_coverage_by_year.csv\n",
        "\"\"\"\n",
        "\n",
        "with open('outputs/results_summary.md', 'w') as f:\n",
        "    f.write(results_summary)\n",
        "\n",
        "print(\"✓ Saved: outputs/results_summary.md\")\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"ANALYSIS COMPLETE\")\n",
        "print(\"=\" * 60)\n",
        "print(\"\\nAll outputs saved to outputs/ directory.\")\n",
        "print(\"See outputs/results_summary.md for full summary.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create README\n",
        "readme_content = \"\"\"# California Medi-Cal Deserts Capstone Project\n",
        "\n",
        "## How to Run\n",
        "\n",
        "1. Ensure all required data files are in the same directory as this notebook:\n",
        "   - county name.xlsx\n",
        "   - medi-cal-enrollment-dashboard-data.csv\n",
        "   - E4 estiamtes.xlsx\n",
        "   - physicians-actively-working-by-specialty-and-patient-care-hours.xlsx\n",
        "   - Primary CAre Shortage .csv\n",
        "   - PQI.csv\n",
        "   - demoACS.csv\n",
        "   - educACS.csv\n",
        "   - EconACS.csv\n",
        "\n",
        "2. Optional files (will be loaded if present):\n",
        "   - pqi-physicians-specialities-list.xlsx\n",
        "   - Other physician activity files\n",
        "   - County shapefile (for maps)\n",
        "\n",
        "3. Run all cells in order (Cell > Run All)\n",
        "\n",
        "4. Outputs will be saved to:\n",
        "   - outputs/data/ - Cleaned datasets\n",
        "   - outputs/figures/ - All figures\n",
        "   - outputs/tables/ - Regression results and diagnostic tables\n",
        "\n",
        "## Dependencies\n",
        "\n",
        "Required:\n",
        "- pandas\n",
        "- numpy\n",
        "- matplotlib\n",
        "- openpyxl (for Excel files)\n",
        "\n",
        "Optional but recommended:\n",
        "- linearmodels (for PanelOLS)\n",
        "- statsmodels (fallback if linearmodels not available)\n",
        "- geopandas (for maps, if shapefile available)\n",
        "\n",
        "## Project Structure\n",
        "\n",
        "The notebook follows this structure:\n",
        "0. Setup & Reproducibility\n",
        "1. Load Raw Data\n",
        "2. Build Clean County Crosswalk\n",
        "3. Clean Population\n",
        "4. Clean Medi-Cal Enrollment\n",
        "5. Clean Physician Supply\n",
        "6. Clean Shortage File\n",
        "7. Clean ACS Controls\n",
        "8. Clean PQI and Build Outcomes\n",
        "9. Build Master Panel\n",
        "10. Descriptive Figures\n",
        "11. Regression Analyses\n",
        "12. Robustness / Sensitivity\n",
        "13. Appendix Diagnostics\n",
        "14. Final Outputs\n",
        "\n",
        "## Key Outputs\n",
        "\n",
        "- **ca_master_panel.csv**: Final county-year panel dataset\n",
        "- **results_summary.md**: Comprehensive results summary\n",
        "- **regression_summary.md**: Regression results interpretation\n",
        "- All figures and tables in outputs/ subdirectories\n",
        "\n",
        "## Notes\n",
        "\n",
        "- The notebook automatically detects whether physician supply and shortage designations are time-varying\n",
        "- Models adapt accordingly (panel vs cross-sectional)\n",
        "- Standard errors are clustered at the county level\n",
        "- Desert definitions use both quartile-based and threshold-based approaches\n",
        "\"\"\"\n",
        "\n",
        "with open('outputs/README.md', 'w') as f:\n",
        "    f.write(readme_content)\n",
        "\n",
        "print(\"✓ Saved: outputs/README.md\")\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"NOTEBOOK COMPLETE - ALL SECTIONS IMPLEMENTED\")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 15) ED Encounters Analysis (New Data Integration)\n",
        "\n",
        "This section integrates Emergency Department encounter data (2012-2023) to:\n",
        "1. Analyze ED utilization patterns across counties\n",
        "2. Test if high ED use indicates lack of primary care access\n",
        "3. Examine ED as a potential mediator between Medi-Cal share and PQI\n",
        "4. Extend time series analysis beyond the Medi-Cal enrollment constraint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load ED Encounters Data\n",
        "print(\"=\" * 60)\n",
        "print(\"LOADING ED ENCOUNTERS DATA\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "encounters_file = 'encounters.csv'\n",
        "if os.path.exists(encounters_file):\n",
        "    df_encounters = pd.read_csv(encounters_file)\n",
        "    print(f\"✓ Loaded encounters.csv: {df_encounters.shape}\")\n",
        "    print(f\"\\nColumns: {list(df_encounters.columns)}\")\n",
        "    print(f\"\\nYear range: {df_encounters['year'].min()} - {df_encounters['year'].max()}\")\n",
        "    print(f\"Unique hospitals: {df_encounters['oshpd_id'].nunique()}\")\n",
        "    print(f\"Unique counties: {df_encounters['county_name'].nunique()}\")\n",
        "    print(f\"\\nEncounter types: {df_encounters['type'].unique()}\")\n",
        "    print(f\"\\nER Service Levels: {df_encounters['er_service_level_desc'].unique()}\")\n",
        "    print(f\"\\nSample data:\")\n",
        "    display(df_encounters.head(10))\n",
        "else:\n",
        "    print(\"ERROR: encounters.csv not found!\")\n",
        "    df_encounters = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clean and Aggregate ED Encounters to County-Year Level\n",
        "print(\"=\" * 60)\n",
        "print(\"AGGREGATING ED ENCOUNTERS TO COUNTY-YEAR LEVEL\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "if df_encounters is not None:\n",
        "    # Standardize county names\n",
        "    df_encounters['county_clean'] = df_encounters['county_name'].apply(standardize_county_name)\n",
        "    \n",
        "    # Pivot to get ED_Visit and ED_Admit as separate columns\n",
        "    encounters_pivot = df_encounters.pivot_table(\n",
        "        index=['year', 'county_clean'],\n",
        "        columns='type',\n",
        "        values='count',\n",
        "        aggfunc='sum'\n",
        "    ).reset_index()\n",
        "    \n",
        "    # Flatten column names\n",
        "    encounters_pivot.columns.name = None\n",
        "    encounters_pivot = encounters_pivot.rename(columns={\n",
        "        'ED_Admit': 'ed_admissions',\n",
        "        'ED_Visit': 'ed_visits'\n",
        "    })\n",
        "    \n",
        "    # Fill NaN with 0 for missing categories\n",
        "    encounters_pivot['ed_admissions'] = encounters_pivot['ed_admissions'].fillna(0)\n",
        "    encounters_pivot['ed_visits'] = encounters_pivot['ed_visits'].fillna(0)\n",
        "    \n",
        "    # Calculate derived metrics\n",
        "    encounters_pivot['ed_total'] = encounters_pivot['ed_visits'] + encounters_pivot['ed_admissions']\n",
        "    encounters_pivot['ed_admit_rate'] = encounters_pivot['ed_admissions'] / encounters_pivot['ed_visits']\n",
        "    encounters_pivot['ed_admit_rate'] = encounters_pivot['ed_admit_rate'].replace([np.inf, -np.inf], np.nan)\n",
        "    \n",
        "    # Merge with crosswalk to get fips5\n",
        "    encounters_county_year = encounters_pivot.merge(\n",
        "        crosswalk_clean[['county_name_clean', 'fips5']],\n",
        "        left_on='county_clean',\n",
        "        right_on='county_name_clean',\n",
        "        how='left'\n",
        "    )\n",
        "    \n",
        "    # Check for unmatched counties\n",
        "    unmatched = encounters_county_year[encounters_county_year['fips5'].isna()]['county_clean'].unique()\n",
        "    if len(unmatched) > 0:\n",
        "        print(f\"⚠️ Warning: {len(unmatched)} counties could not be matched to FIPS:\")\n",
        "        print(unmatched[:10])\n",
        "    \n",
        "    # Drop unmatched and clean up\n",
        "    encounters_county_year = encounters_county_year[encounters_county_year['fips5'].notna()].copy()\n",
        "    encounters_county_year = encounters_county_year[['fips5', 'year', 'ed_visits', 'ed_admissions', \n",
        "                                                       'ed_total', 'ed_admit_rate']]\n",
        "    \n",
        "    print(f\"\\n✓ Created county-year ED encounters dataset:\")\n",
        "    print(f\"  Shape: {encounters_county_year.shape}\")\n",
        "    print(f\"  Year range: {encounters_county_year['year'].min()} - {encounters_county_year['year'].max()}\")\n",
        "    print(f\"  Unique counties: {encounters_county_year['fips5'].nunique()}\")\n",
        "    \n",
        "    # Summary stats\n",
        "    print(f\"\\n--- ED Summary Statistics ---\")\n",
        "    print(encounters_county_year[['ed_visits', 'ed_admissions', 'ed_total', 'ed_admit_rate']].describe())\n",
        "    \n",
        "    # Save\n",
        "    encounters_county_year.to_csv('outputs/data/ed_encounters_county_year.csv', index=False)\n",
        "    print(f\"\\n✓ Saved: outputs/data/ed_encounters_county_year.csv\")\n",
        "else:\n",
        "    encounters_county_year = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate ED Per Capita Rates and Merge with Population\n",
        "print(\"=\" * 60)\n",
        "print(\"CALCULATING ED PER CAPITA RATES\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "if encounters_county_year is not None:\n",
        "    # Merge with population data\n",
        "    ed_with_pop = encounters_county_year.merge(\n",
        "        pop_year[['fips5', 'year', 'population']],\n",
        "        on=['fips5', 'year'],\n",
        "        how='left'\n",
        "    )\n",
        "    \n",
        "    # Calculate per capita rates (per 1,000 population)\n",
        "    ed_with_pop['ed_visits_per_1k'] = (ed_with_pop['ed_visits'] / ed_with_pop['population']) * 1000\n",
        "    ed_with_pop['ed_admits_per_1k'] = (ed_with_pop['ed_admissions'] / ed_with_pop['population']) * 1000\n",
        "    ed_with_pop['ed_total_per_1k'] = (ed_with_pop['ed_total'] / ed_with_pop['population']) * 1000\n",
        "    \n",
        "    # Check population merge success\n",
        "    pop_matched = ed_with_pop['population'].notna().sum()\n",
        "    print(f\"✓ Population matched for {pop_matched}/{len(ed_with_pop)} records ({100*pop_matched/len(ed_with_pop):.1f}%)\")\n",
        "    \n",
        "    # Summary of per-capita rates\n",
        "    print(f\"\\n--- ED Per 1,000 Population Statistics ---\")\n",
        "    print(ed_with_pop[['ed_visits_per_1k', 'ed_admits_per_1k', 'ed_total_per_1k', 'ed_admit_rate']].describe())\n",
        "    \n",
        "    # Save enhanced dataset\n",
        "    ed_with_pop.to_csv('outputs/data/ed_encounters_with_rates.csv', index=False)\n",
        "    print(f\"\\n✓ Saved: outputs/data/ed_encounters_with_rates.csv\")\n",
        "    \n",
        "    encounters_county_year = ed_with_pop.copy()\n",
        "else:\n",
        "    print(\"No encounters data to process.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ED Utilization Time Series (2012-2023)\n",
        "print(\"=\" * 60)\n",
        "print(\"ED UTILIZATION TIME SERIES ANALYSIS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "if encounters_county_year is not None:\n",
        "    # Aggregate to statewide by year (weighted by population)\n",
        "    ed_state_year = encounters_county_year.groupby('year').agg({\n",
        "        'ed_visits': 'sum',\n",
        "        'ed_admissions': 'sum',\n",
        "        'ed_total': 'sum',\n",
        "        'population': 'sum'\n",
        "    }).reset_index()\n",
        "    \n",
        "    # Calculate statewide rates\n",
        "    ed_state_year['ed_visits_per_1k'] = (ed_state_year['ed_visits'] / ed_state_year['population']) * 1000\n",
        "    ed_state_year['ed_admits_per_1k'] = (ed_state_year['ed_admissions'] / ed_state_year['population']) * 1000\n",
        "    ed_state_year['ed_admit_rate'] = ed_state_year['ed_admissions'] / ed_state_year['ed_visits']\n",
        "    \n",
        "    print(\"Statewide ED Trends (2012-2023):\")\n",
        "    print(ed_state_year[['year', 'ed_visits', 'ed_visits_per_1k', 'ed_admit_rate']].to_string(index=False))\n",
        "    \n",
        "    # Create time series figure\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "    \n",
        "    # Plot 1: Total ED Visits\n",
        "    ax1 = axes[0, 0]\n",
        "    ax1.plot(ed_state_year['year'], ed_state_year['ed_visits']/1e6, 'b-o', linewidth=2, markersize=6)\n",
        "    ax1.set_xlabel('Year', fontsize=11)\n",
        "    ax1.set_ylabel('ED Visits (Millions)', fontsize=11)\n",
        "    ax1.set_title('Total Statewide ED Visits', fontsize=12, fontweight='bold')\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "    ax1.axvline(x=2020, color='red', linestyle='--', alpha=0.5, label='COVID-19')\n",
        "    ax1.legend()\n",
        "    \n",
        "    # Plot 2: ED Visits per 1,000\n",
        "    ax2 = axes[0, 1]\n",
        "    ax2.plot(ed_state_year['year'], ed_state_year['ed_visits_per_1k'], 'g-o', linewidth=2, markersize=6)\n",
        "    ax2.set_xlabel('Year', fontsize=11)\n",
        "    ax2.set_ylabel('ED Visits per 1,000 Population', fontsize=11)\n",
        "    ax2.set_title('ED Utilization Rate (per 1,000)', fontsize=12, fontweight='bold')\n",
        "    ax2.grid(True, alpha=0.3)\n",
        "    ax2.axvline(x=2020, color='red', linestyle='--', alpha=0.5, label='COVID-19')\n",
        "    ax2.legend()\n",
        "    \n",
        "    # Plot 3: ED Admission Rate\n",
        "    ax3 = axes[1, 0]\n",
        "    ax3.plot(ed_state_year['year'], ed_state_year['ed_admit_rate']*100, 'r-o', linewidth=2, markersize=6)\n",
        "    ax3.set_xlabel('Year', fontsize=11)\n",
        "    ax3.set_ylabel('ED Admission Rate (%)', fontsize=11)\n",
        "    ax3.set_title('ED-to-Admission Conversion Rate', fontsize=12, fontweight='bold')\n",
        "    ax3.grid(True, alpha=0.3)\n",
        "    ax3.axvline(x=2020, color='red', linestyle='--', alpha=0.5, label='COVID-19')\n",
        "    ax3.legend()\n",
        "    \n",
        "    # Plot 4: ED Admissions per 1,000\n",
        "    ax4 = axes[1, 1]\n",
        "    ax4.plot(ed_state_year['year'], ed_state_year['ed_admits_per_1k'], 'm-o', linewidth=2, markersize=6)\n",
        "    ax4.set_xlabel('Year', fontsize=11)\n",
        "    ax4.set_ylabel('ED Admissions per 1,000 Population', fontsize=11)\n",
        "    ax4.set_title('ED Admissions Rate (per 1,000)', fontsize=12, fontweight='bold')\n",
        "    ax4.grid(True, alpha=0.3)\n",
        "    ax4.axvline(x=2020, color='red', linestyle='--', alpha=0.5, label='COVID-19')\n",
        "    ax4.legend()\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig('outputs/figures/ed_trends_2012_2023.png', dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    print(\"\\n✓ Saved: outputs/figures/ed_trends_2012_2023.png\")\n",
        "    \n",
        "    # Save statewide data\n",
        "    ed_state_year.to_csv('outputs/data/ed_statewide_trends.csv', index=False)\n",
        "    print(\"✓ Saved: outputs/data/ed_statewide_trends.csv\")\n",
        "else:\n",
        "    print(\"No ED data available for time series analysis.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# County-Level ED Variation Analysis\n",
        "print(\"=\" * 60)\n",
        "print(\"COUNTY-LEVEL ED VARIATION ANALYSIS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "if encounters_county_year is not None:\n",
        "    # Get latest year data (2023) for comparison\n",
        "    latest_year = encounters_county_year['year'].max()\n",
        "    ed_latest = encounters_county_year[encounters_county_year['year'] == latest_year].copy()\n",
        "    \n",
        "    # Merge with crosswalk to get county names\n",
        "    ed_latest = ed_latest.merge(\n",
        "        crosswalk_clean[['fips5', 'county_name_clean']],\n",
        "        on='fips5',\n",
        "        how='left'\n",
        "    )\n",
        "    \n",
        "    # Sort by ED visit rate\n",
        "    ed_latest_sorted = ed_latest.sort_values('ed_visits_per_1k', ascending=False)\n",
        "    \n",
        "    print(f\"\\n--- Top 10 Counties by ED Visits per 1,000 ({latest_year}) ---\")\n",
        "    print(ed_latest_sorted[['county_name_clean', 'ed_visits_per_1k', 'ed_admit_rate', 'population']].head(10).to_string(index=False))\n",
        "    \n",
        "    print(f\"\\n--- Bottom 10 Counties by ED Visits per 1,000 ({latest_year}) ---\")\n",
        "    print(ed_latest_sorted[['county_name_clean', 'ed_visits_per_1k', 'ed_admit_rate', 'population']].tail(10).to_string(index=False))\n",
        "    \n",
        "    # Create county comparison figure\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
        "    \n",
        "    # Plot 1: Top/Bottom 15 counties by ED visit rate\n",
        "    ax1 = axes[0]\n",
        "    top_15 = ed_latest_sorted.head(15)\n",
        "    bottom_15 = ed_latest_sorted.tail(15)\n",
        "    combined = pd.concat([top_15, bottom_15])\n",
        "    \n",
        "    colors = ['#d62728' if x in top_15['fips5'].values else '#2ca02c' for x in combined['fips5']]\n",
        "    bars = ax1.barh(range(len(combined)), combined['ed_visits_per_1k'], color=colors)\n",
        "    ax1.set_yticks(range(len(combined)))\n",
        "    ax1.set_yticklabels(combined['county_name_clean'], fontsize=8)\n",
        "    ax1.set_xlabel('ED Visits per 1,000 Population', fontsize=11)\n",
        "    ax1.set_title(f'Top 15 (Red) and Bottom 15 (Green) Counties\\nby ED Utilization Rate ({latest_year})', fontsize=12, fontweight='bold')\n",
        "    ax1.grid(True, alpha=0.3, axis='x')\n",
        "    \n",
        "    # Plot 2: ED Admission Rate vs ED Visit Rate scatter\n",
        "    ax2 = axes[1]\n",
        "    scatter = ax2.scatter(ed_latest['ed_visits_per_1k'], ed_latest['ed_admit_rate']*100, \n",
        "                          s=ed_latest['population']/10000, alpha=0.6, c='steelblue', edgecolors='black', linewidth=0.5)\n",
        "    ax2.set_xlabel('ED Visits per 1,000 Population', fontsize=11)\n",
        "    ax2.set_ylabel('ED Admission Rate (%)', fontsize=11)\n",
        "    ax2.set_title(f'ED Visit Rate vs Admission Rate by County ({latest_year})\\n(Bubble size = Population)', fontsize=12, fontweight='bold')\n",
        "    ax2.grid(True, alpha=0.3)\n",
        "    \n",
        "    # Label extreme outliers\n",
        "    for idx, row in ed_latest.nlargest(5, 'ed_visits_per_1k').iterrows():\n",
        "        ax2.annotate(row['county_name_clean'], (row['ed_visits_per_1k'], row['ed_admit_rate']*100),\n",
        "                     fontsize=8, alpha=0.8, ha='left')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig('outputs/figures/ed_county_comparison.png', dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    print(\"\\n✓ Saved: outputs/figures/ed_county_comparison.png\")\n",
        "else:\n",
        "    print(\"No ED data available for county comparison.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Merge ED Data with Master Panel for Regression Analysis\n",
        "print(\"=\" * 60)\n",
        "print(\"MERGING ED DATA WITH MASTER PANEL\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "if encounters_county_year is not None and master_panel is not None:\n",
        "    # Get year from master panel\n",
        "    panel_year = master_panel['year'].iloc[0] if 'year' in master_panel.columns else 2020\n",
        "    print(f\"Master panel year: {panel_year}\")\n",
        "    \n",
        "    # Filter ED data to matching year\n",
        "    ed_for_merge = encounters_county_year[encounters_county_year['year'] == panel_year].copy()\n",
        "    print(f\"ED records for {panel_year}: {len(ed_for_merge)}\")\n",
        "    \n",
        "    # Merge with master panel\n",
        "    master_with_ed = master_panel.merge(\n",
        "        ed_for_merge[['fips5', 'ed_visits', 'ed_admissions', 'ed_visits_per_1k', 'ed_admits_per_1k', 'ed_admit_rate']],\n",
        "        on='fips5',\n",
        "        how='left'\n",
        "    )\n",
        "    \n",
        "    # Check merge success\n",
        "    ed_matched = master_with_ed['ed_visits_per_1k'].notna().sum()\n",
        "    print(f\"✓ ED data matched for {ed_matched}/{len(master_with_ed)} counties ({100*ed_matched/len(master_with_ed):.1f}%)\")\n",
        "    \n",
        "    # Summary of ED metrics in merged data\n",
        "    print(f\"\\n--- ED Metrics in Master Panel ({panel_year}) ---\")\n",
        "    print(master_with_ed[['ed_visits_per_1k', 'ed_admits_per_1k', 'ed_admit_rate']].describe())\n",
        "    \n",
        "    # Correlation with key variables\n",
        "    print(f\"\\n--- Correlations with ED Visits per 1k ---\")\n",
        "    ed_corr_vars = ['pqi_mean_rate', 'medi_cal_share', 'pcp_per_100k', 'poverty_pct']\n",
        "    available_vars = [v for v in ed_corr_vars if v in master_with_ed.columns]\n",
        "    for var in available_vars:\n",
        "        corr = master_with_ed[['ed_visits_per_1k', var]].corr().iloc[0, 1]\n",
        "        print(f\"  ED visits per 1k vs {var}: {corr:.3f}\")\n",
        "    \n",
        "    # Save enhanced panel\n",
        "    master_with_ed.to_csv('outputs/data/ca_master_panel_with_ed.csv', index=False)\n",
        "    print(f\"\\n✓ Saved: outputs/data/ca_master_panel_with_ed.csv\")\n",
        "else:\n",
        "    master_with_ed = None\n",
        "    print(\"Cannot merge - missing ED data or master panel.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ED Regression Analysis\n",
        "print(\"=\" * 60)\n",
        "print(\"ED REGRESSION ANALYSIS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.regression.linear_model import OLS\n",
        "\n",
        "if master_with_ed is not None:\n",
        "    # Prepare data - drop NaN for analysis\n",
        "    ed_analysis = master_with_ed.dropna(subset=['ed_visits_per_1k', 'pqi_mean_rate', 'medi_cal_share']).copy()\n",
        "    print(f\"Analysis sample: {len(ed_analysis)} counties\")\n",
        "    \n",
        "    # Define controls\n",
        "    control_vars = ['poverty_pct', 'unemp_pct', 'age65_pct', 'hispanic_pct', 'bachelors_pct']\n",
        "    available_controls = [v for v in control_vars if v in ed_analysis.columns and ed_analysis[v].notna().sum() > 0]\n",
        "    print(f\"Available controls: {available_controls}\")\n",
        "    \n",
        "    results_list = []\n",
        "    \n",
        "    # =========================================\n",
        "    # Model E1: ED Visits as Outcome\n",
        "    # Does Medi-Cal share predict ED utilization?\n",
        "    # =========================================\n",
        "    print(\"\\n\" + \"=\" * 50)\n",
        "    print(\"MODEL E1: What predicts ED Utilization?\")\n",
        "    print(\"DV: ED Visits per 1,000 Population\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    Y_e1 = ed_analysis['ed_visits_per_1k']\n",
        "    X_vars_e1 = ['medi_cal_share']\n",
        "    if 'pcp_per_100k' in ed_analysis.columns:\n",
        "        X_vars_e1.append('pcp_per_100k')\n",
        "    X_vars_e1.extend(available_controls)\n",
        "    \n",
        "    X_e1 = ed_analysis[X_vars_e1].dropna()\n",
        "    Y_e1 = Y_e1.loc[X_e1.index]\n",
        "    X_e1 = sm.add_constant(X_e1)\n",
        "    \n",
        "    model_e1 = OLS(Y_e1, X_e1).fit(cov_type='HC1')\n",
        "    print(model_e1.summary2().tables[1])\n",
        "    \n",
        "    # Store results\n",
        "    results_list.append({\n",
        "        'Model': 'E1: ED Utilization',\n",
        "        'DV': 'ED Visits per 1k',\n",
        "        'Medi-Cal Coef': model_e1.params.get('medi_cal_share', np.nan),\n",
        "        'Medi-Cal P-value': model_e1.pvalues.get('medi_cal_share', np.nan),\n",
        "        'R2': model_e1.rsquared,\n",
        "        'N': int(model_e1.nobs)\n",
        "    })\n",
        "    \n",
        "    # Interpretation\n",
        "    mc_coef_e1 = model_e1.params.get('medi_cal_share', 0)\n",
        "    print(f\"\\n**Interpretation:** A +10 percentage point increase in Medi-Cal share\")\n",
        "    print(f\"is associated with {mc_coef_e1 * 0.10:.1f} more ED visits per 1,000 population.\")\n",
        "    \n",
        "    # =========================================\n",
        "    # Model E2: ED as Mediator between Medi-Cal and PQI\n",
        "    # Does ED utilization explain the Medi-Cal → PQI relationship?\n",
        "    # =========================================\n",
        "    print(\"\\n\" + \"=\" * 50)\n",
        "    print(\"MODEL E2: PQI with ED as Additional Predictor\")\n",
        "    print(\"DV: PQI Mean Rate (Preventable Hospitalizations)\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    # First: PQI without ED (baseline)\n",
        "    Y_e2 = ed_analysis['pqi_mean_rate']\n",
        "    X_vars_baseline = ['medi_cal_share'] + available_controls\n",
        "    if 'pcp_per_100k' in ed_analysis.columns:\n",
        "        X_vars_baseline.insert(1, 'pcp_per_100k')\n",
        "    \n",
        "    X_baseline = ed_analysis[X_vars_baseline].dropna()\n",
        "    Y_baseline = Y_e2.loc[X_baseline.index]\n",
        "    X_baseline_const = sm.add_constant(X_baseline)\n",
        "    \n",
        "    model_baseline = OLS(Y_baseline, X_baseline_const).fit(cov_type='HC1')\n",
        "    mc_coef_baseline = model_baseline.params.get('medi_cal_share', 0)\n",
        "    \n",
        "    # Second: PQI with ED\n",
        "    X_vars_with_ed = ['medi_cal_share', 'ed_visits_per_1k'] + available_controls\n",
        "    if 'pcp_per_100k' in ed_analysis.columns:\n",
        "        X_vars_with_ed.insert(2, 'pcp_per_100k')\n",
        "    \n",
        "    X_with_ed = ed_analysis[X_vars_with_ed].dropna()\n",
        "    Y_with_ed = Y_e2.loc[X_with_ed.index]\n",
        "    X_with_ed_const = sm.add_constant(X_with_ed)\n",
        "    \n",
        "    model_with_ed = OLS(Y_with_ed, X_with_ed_const).fit(cov_type='HC1')\n",
        "    mc_coef_with_ed = model_with_ed.params.get('medi_cal_share', 0)\n",
        "    \n",
        "    print(\"Without ED control:\")\n",
        "    print(f\"  Medi-Cal coef: {mc_coef_baseline:.2f}\")\n",
        "    print(\"\\nWith ED control:\")\n",
        "    print(model_with_ed.summary2().tables[1])\n",
        "    \n",
        "    # Calculate mediation\n",
        "    pct_mediated = (mc_coef_baseline - mc_coef_with_ed) / mc_coef_baseline * 100 if mc_coef_baseline != 0 else np.nan\n",
        "    print(f\"\\n**Mediation Analysis:**\")\n",
        "    print(f\"  Medi-Cal coef without ED: {mc_coef_baseline:.2f}\")\n",
        "    print(f\"  Medi-Cal coef with ED: {mc_coef_with_ed:.2f}\")\n",
        "    print(f\"  % of effect mediated by ED: {pct_mediated:.1f}%\")\n",
        "    \n",
        "    results_list.append({\n",
        "        'Model': 'E2: PQI with ED',\n",
        "        'DV': 'PQI Mean Rate',\n",
        "        'Medi-Cal Coef': mc_coef_with_ed,\n",
        "        'Medi-Cal P-value': model_with_ed.pvalues.get('medi_cal_share', np.nan),\n",
        "        'R2': model_with_ed.rsquared,\n",
        "        'N': int(model_with_ed.nobs)\n",
        "    })\n",
        "    \n",
        "    # =========================================\n",
        "    # Model E3: Does ED predict PQI independently?\n",
        "    # =========================================\n",
        "    print(\"\\n\" + \"=\" * 50)\n",
        "    print(\"MODEL E3: ED → PQI Relationship\")\n",
        "    print(\"DV: PQI Mean Rate\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    ed_coef = model_with_ed.params.get('ed_visits_per_1k', 0)\n",
        "    ed_pval = model_with_ed.pvalues.get('ed_visits_per_1k', np.nan)\n",
        "    \n",
        "    print(f\"ED Visits per 1k coefficient: {ed_coef:.4f}\")\n",
        "    print(f\"P-value: {ed_pval:.4f}\")\n",
        "    print(f\"\\n**Interpretation:** Each additional 10 ED visits per 1k population\")\n",
        "    print(f\"is associated with {ed_coef * 10:.2f} higher PQI rate.\")\n",
        "    \n",
        "    results_list.append({\n",
        "        'Model': 'E3: ED → PQI',\n",
        "        'DV': 'PQI Mean Rate',\n",
        "        'Medi-Cal Coef': ed_coef,\n",
        "        'Medi-Cal P-value': ed_pval,\n",
        "        'R2': model_with_ed.rsquared,\n",
        "        'N': int(model_with_ed.nobs)\n",
        "    })\n",
        "    \n",
        "    # Save results\n",
        "    ed_results_df = pd.DataFrame(results_list)\n",
        "    ed_results_df.to_csv('outputs/tables/ed_regression_results.csv', index=False)\n",
        "    print(f\"\\n✓ Saved: outputs/tables/ed_regression_results.csv\")\n",
        "    \n",
        "else:\n",
        "    print(\"Cannot run ED regressions - missing merged data.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ED Utilization in Desert vs Non-Desert Counties\n",
        "print(\"=\" * 60)\n",
        "print(\"ED UTILIZATION: DESERT vs NON-DESERT COMPARISON\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "if master_with_ed is not None:\n",
        "    # Check if desert columns exist\n",
        "    desert_cols = [c for c in master_with_ed.columns if 'desert' in c.lower()]\n",
        "    print(f\"Desert columns available: {desert_cols}\")\n",
        "    \n",
        "    if 'desert_thr_def2' in master_with_ed.columns or 'desert_q_def2' in master_with_ed.columns:\n",
        "        desert_col = 'desert_thr_def2' if 'desert_thr_def2' in master_with_ed.columns else 'desert_q_def2'\n",
        "        \n",
        "        # Filter to non-missing ED data\n",
        "        ed_desert = master_with_ed[master_with_ed['ed_visits_per_1k'].notna()].copy()\n",
        "        \n",
        "        # Compare means\n",
        "        desert_group = ed_desert.groupby(desert_col).agg({\n",
        "            'ed_visits_per_1k': ['mean', 'std', 'count'],\n",
        "            'ed_admits_per_1k': ['mean', 'std'],\n",
        "            'ed_admit_rate': ['mean', 'std'],\n",
        "            'pqi_mean_rate': ['mean', 'std']\n",
        "        }).round(2)\n",
        "        \n",
        "        print(f\"\\n--- ED Metrics by Desert Status ({desert_col}) ---\")\n",
        "        print(desert_group)\n",
        "        \n",
        "        # Calculate difference\n",
        "        non_desert = ed_desert[ed_desert[desert_col] == 0]\n",
        "        desert = ed_desert[ed_desert[desert_col] == 1]\n",
        "        \n",
        "        print(f\"\\n--- Summary ---\")\n",
        "        print(f\"Non-Desert counties: {len(non_desert)}\")\n",
        "        print(f\"Desert counties: {len(desert)}\")\n",
        "        \n",
        "        if len(desert) > 0 and len(non_desert) > 0:\n",
        "            ed_diff = desert['ed_visits_per_1k'].mean() - non_desert['ed_visits_per_1k'].mean()\n",
        "            pqi_diff = desert['pqi_mean_rate'].mean() - non_desert['pqi_mean_rate'].mean()\n",
        "            \n",
        "            print(f\"\\nED Visits per 1k: Desert = {desert['ed_visits_per_1k'].mean():.1f}, Non-Desert = {non_desert['ed_visits_per_1k'].mean():.1f}\")\n",
        "            print(f\"  Difference: {ed_diff:+.1f} ({100*ed_diff/non_desert['ed_visits_per_1k'].mean():+.1f}%)\")\n",
        "            print(f\"\\nPQI Rate: Desert = {desert['pqi_mean_rate'].mean():.1f}, Non-Desert = {non_desert['pqi_mean_rate'].mean():.1f}\")\n",
        "            print(f\"  Difference: {pqi_diff:+.1f} ({100*pqi_diff/non_desert['pqi_mean_rate'].mean():+.1f}%)\")\n",
        "        \n",
        "        # Visualization\n",
        "        fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "        \n",
        "        # Plot 1: ED Visits by Desert Status\n",
        "        ax1 = axes[0]\n",
        "        desert_means = [non_desert['ed_visits_per_1k'].mean(), desert['ed_visits_per_1k'].mean()]\n",
        "        desert_stds = [non_desert['ed_visits_per_1k'].std(), desert['ed_visits_per_1k'].std()]\n",
        "        bars1 = ax1.bar(['Non-Desert', 'Desert'], desert_means, yerr=desert_stds, capsize=5, \n",
        "                        color=['#2ca02c', '#d62728'], edgecolor='black', linewidth=1.5)\n",
        "        ax1.set_ylabel('ED Visits per 1,000 Population', fontsize=11)\n",
        "        ax1.set_title('ED Utilization by Desert Status', fontsize=12, fontweight='bold')\n",
        "        ax1.grid(True, alpha=0.3, axis='y')\n",
        "        \n",
        "        # Plot 2: ED Admission Rate by Desert Status\n",
        "        ax2 = axes[1]\n",
        "        admit_means = [non_desert['ed_admit_rate'].mean()*100, desert['ed_admit_rate'].mean()*100]\n",
        "        admit_stds = [non_desert['ed_admit_rate'].std()*100, desert['ed_admit_rate'].std()*100]\n",
        "        bars2 = ax2.bar(['Non-Desert', 'Desert'], admit_means, yerr=admit_stds, capsize=5,\n",
        "                        color=['#2ca02c', '#d62728'], edgecolor='black', linewidth=1.5)\n",
        "        ax2.set_ylabel('ED Admission Rate (%)', fontsize=11)\n",
        "        ax2.set_title('ED Admission Rate by Desert Status', fontsize=12, fontweight='bold')\n",
        "        ax2.grid(True, alpha=0.3, axis='y')\n",
        "        \n",
        "        # Plot 3: Scatter - ED vs PQI colored by desert\n",
        "        ax3 = axes[2]\n",
        "        ax3.scatter(non_desert['ed_visits_per_1k'], non_desert['pqi_mean_rate'], \n",
        "                   c='#2ca02c', alpha=0.6, s=80, label='Non-Desert', edgecolors='black', linewidth=0.5)\n",
        "        ax3.scatter(desert['ed_visits_per_1k'], desert['pqi_mean_rate'], \n",
        "                   c='#d62728', alpha=0.6, s=80, label='Desert', edgecolors='black', linewidth=0.5)\n",
        "        ax3.set_xlabel('ED Visits per 1,000 Population', fontsize=11)\n",
        "        ax3.set_ylabel('PQI Mean Rate', fontsize=11)\n",
        "        ax3.set_title('ED Utilization vs PQI by Desert Status', fontsize=12, fontweight='bold')\n",
        "        ax3.legend()\n",
        "        ax3.grid(True, alpha=0.3)\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.savefig('outputs/figures/ed_desert_comparison.png', dpi=150, bbox_inches='tight')\n",
        "        plt.show()\n",
        "        print(\"\\n✓ Saved: outputs/figures/ed_desert_comparison.png\")\n",
        "    else:\n",
        "        print(\"No desert classification columns found.\")\n",
        "else:\n",
        "    print(\"No merged data available for desert comparison.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extended Time Series: ED and PQI (2012-2023)\n",
        "print(\"=\" * 60)\n",
        "print(\"EXTENDED TIME SERIES: ED AND PQI (2012-2023)\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "if encounters_county_year is not None and 'pqi_county_year' in dir():\n",
        "    # Merge ED with PQI for overlapping years\n",
        "    ed_pqi_panel = encounters_county_year.merge(\n",
        "        pqi_county_year[['fips5', 'year', 'pqi_mean_rate', 'pqi_sum_count', 'pqi_sum_population']],\n",
        "        on=['fips5', 'year'],\n",
        "        how='inner'\n",
        "    )\n",
        "    \n",
        "    print(f\"ED + PQI merged panel:\")\n",
        "    print(f\"  Shape: {ed_pqi_panel.shape}\")\n",
        "    print(f\"  Year range: {ed_pqi_panel['year'].min()} - {ed_pqi_panel['year'].max()}\")\n",
        "    print(f\"  Unique counties: {ed_pqi_panel['fips5'].nunique()}\")\n",
        "    \n",
        "    # Aggregate to statewide trends\n",
        "    ed_pqi_state = ed_pqi_panel.groupby('year').agg({\n",
        "        'ed_visits': 'sum',\n",
        "        'ed_admissions': 'sum',\n",
        "        'population': 'sum',\n",
        "        'pqi_sum_count': 'sum',\n",
        "        'pqi_sum_population': 'sum'\n",
        "    }).reset_index()\n",
        "    \n",
        "    # Calculate rates\n",
        "    ed_pqi_state['ed_visits_per_1k'] = (ed_pqi_state['ed_visits'] / ed_pqi_state['population']) * 1000\n",
        "    ed_pqi_state['pqi_rate_per_100k'] = (ed_pqi_state['pqi_sum_count'] / ed_pqi_state['pqi_sum_population']) * 100000\n",
        "    \n",
        "    print(f\"\\n--- Statewide ED and PQI Trends ---\")\n",
        "    print(ed_pqi_state[['year', 'ed_visits_per_1k', 'pqi_rate_per_100k']].to_string(index=False))\n",
        "    \n",
        "    # Create combined time series figure\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "    \n",
        "    # Plot 1: ED and PQI trends (dual axis)\n",
        "    ax1 = axes[0, 0]\n",
        "    ax1_twin = ax1.twinx()\n",
        "    \n",
        "    line1 = ax1.plot(ed_pqi_state['year'], ed_pqi_state['ed_visits_per_1k'], 'b-o', \n",
        "                     linewidth=2, markersize=6, label='ED Visits per 1k')\n",
        "    line2 = ax1_twin.plot(ed_pqi_state['year'], ed_pqi_state['pqi_rate_per_100k'], 'r-s', \n",
        "                          linewidth=2, markersize=6, label='PQI Rate per 100k')\n",
        "    \n",
        "    ax1.set_xlabel('Year', fontsize=11)\n",
        "    ax1.set_ylabel('ED Visits per 1,000', color='blue', fontsize=11)\n",
        "    ax1_twin.set_ylabel('PQI Rate per 100,000', color='red', fontsize=11)\n",
        "    ax1.set_title('ED Utilization and Preventable Hospitalizations\\n(Statewide Trends)', fontsize=12, fontweight='bold')\n",
        "    ax1.axvline(x=2020, color='gray', linestyle='--', alpha=0.5, label='COVID-19')\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "    \n",
        "    # Combine legends\n",
        "    lines = line1 + line2\n",
        "    labels = [l.get_label() for l in lines]\n",
        "    ax1.legend(lines, labels, loc='upper left')\n",
        "    \n",
        "    # Plot 2: Year-over-year changes\n",
        "    ax2 = axes[0, 1]\n",
        "    ed_pqi_state['ed_change'] = ed_pqi_state['ed_visits_per_1k'].pct_change() * 100\n",
        "    ed_pqi_state['pqi_change'] = ed_pqi_state['pqi_rate_per_100k'].pct_change() * 100\n",
        "    \n",
        "    ax2.bar(ed_pqi_state['year'][1:] - 0.2, ed_pqi_state['ed_change'][1:], width=0.4, \n",
        "            label='ED Change (%)', color='steelblue', edgecolor='black')\n",
        "    ax2.bar(ed_pqi_state['year'][1:] + 0.2, ed_pqi_state['pqi_change'][1:], width=0.4,\n",
        "            label='PQI Change (%)', color='firebrick', edgecolor='black')\n",
        "    ax2.axhline(y=0, color='black', linewidth=0.5)\n",
        "    ax2.set_xlabel('Year', fontsize=11)\n",
        "    ax2.set_ylabel('Year-over-Year Change (%)', fontsize=11)\n",
        "    ax2.set_title('Annual Changes in ED and PQI', fontsize=12, fontweight='bold')\n",
        "    ax2.legend()\n",
        "    ax2.grid(True, alpha=0.3, axis='y')\n",
        "    \n",
        "    # Plot 3: Correlation over time (scatter with years labeled)\n",
        "    ax3 = axes[1, 0]\n",
        "    scatter = ax3.scatter(ed_pqi_state['ed_visits_per_1k'], ed_pqi_state['pqi_rate_per_100k'],\n",
        "                          c=ed_pqi_state['year'], cmap='viridis', s=100, edgecolors='black', linewidth=1)\n",
        "    for idx, row in ed_pqi_state.iterrows():\n",
        "        ax3.annotate(str(int(row['year'])), (row['ed_visits_per_1k'], row['pqi_rate_per_100k']),\n",
        "                     fontsize=9, ha='left', va='bottom')\n",
        "    ax3.set_xlabel('ED Visits per 1,000', fontsize=11)\n",
        "    ax3.set_ylabel('PQI Rate per 100,000', fontsize=11)\n",
        "    ax3.set_title('ED vs PQI Over Time (State-Level)', fontsize=12, fontweight='bold')\n",
        "    cbar = plt.colorbar(scatter, ax=ax3)\n",
        "    cbar.set_label('Year')\n",
        "    ax3.grid(True, alpha=0.3)\n",
        "    \n",
        "    # Plot 4: Indexed trends (2012 = 100)\n",
        "    ax4 = axes[1, 1]\n",
        "    base_ed = ed_pqi_state['ed_visits_per_1k'].iloc[0]\n",
        "    base_pqi = ed_pqi_state['pqi_rate_per_100k'].iloc[0]\n",
        "    \n",
        "    ed_pqi_state['ed_indexed'] = (ed_pqi_state['ed_visits_per_1k'] / base_ed) * 100\n",
        "    ed_pqi_state['pqi_indexed'] = (ed_pqi_state['pqi_rate_per_100k'] / base_pqi) * 100\n",
        "    \n",
        "    ax4.plot(ed_pqi_state['year'], ed_pqi_state['ed_indexed'], 'b-o', linewidth=2, markersize=6, label='ED Visits')\n",
        "    ax4.plot(ed_pqi_state['year'], ed_pqi_state['pqi_indexed'], 'r-s', linewidth=2, markersize=6, label='PQI Rate')\n",
        "    ax4.axhline(y=100, color='gray', linestyle='--', alpha=0.5)\n",
        "    ax4.axvline(x=2020, color='gray', linestyle='--', alpha=0.5, label='COVID-19')\n",
        "    ax4.set_xlabel('Year', fontsize=11)\n",
        "    ax4.set_ylabel('Index (2012 = 100)', fontsize=11)\n",
        "    ax4.set_title('Indexed Trends: ED and PQI\\n(Base Year 2012 = 100)', fontsize=12, fontweight='bold')\n",
        "    ax4.legend()\n",
        "    ax4.grid(True, alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig('outputs/figures/ed_pqi_time_series.png', dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    print(\"\\n✓ Saved: outputs/figures/ed_pqi_time_series.png\")\n",
        "    \n",
        "    # Calculate correlation\n",
        "    corr = ed_pqi_state['ed_visits_per_1k'].corr(ed_pqi_state['pqi_rate_per_100k'])\n",
        "    print(f\"\\nState-level correlation (ED vs PQI over time): {corr:.3f}\")\n",
        "    \n",
        "    # Save panel data\n",
        "    ed_pqi_panel.to_csv('outputs/data/ed_pqi_county_year_panel.csv', index=False)\n",
        "    ed_pqi_state.to_csv('outputs/data/ed_pqi_statewide_trends.csv', index=False)\n",
        "    print(\"✓ Saved: outputs/data/ed_pqi_county_year_panel.csv\")\n",
        "    print(\"✓ Saved: outputs/data/ed_pqi_statewide_trends.csv\")\n",
        "    \n",
        "else:\n",
        "    print(\"Cannot create extended time series - missing ED or PQI data.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ED Analysis Summary\n",
        "print(\"=\" * 60)\n",
        "print(\"ED ENCOUNTERS ANALYSIS SUMMARY\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "ed_summary = \"\"\"\n",
        "## ED Encounters Analysis Summary\n",
        "\n",
        "### Data Overview\n",
        "- **Source:** California OSHPD/HCAI Emergency Department Encounters\n",
        "- **Years:** 2012-2023 (12 years of time series data)\n",
        "- **Coverage:** ~55 counties with hospital ED services\n",
        "- **Metrics:** ED visits, ED admissions, admission rates\n",
        "\n",
        "### Key Findings\n",
        "\n",
        "#### 1. Statewide Trends (2012-2023)\n",
        "- ED utilization declined significantly during COVID-19 (2020)\n",
        "- Post-pandemic recovery shows return to pre-COVID levels\n",
        "- ED admission rates have remained relatively stable\n",
        "\n",
        "#### 2. County Variation\n",
        "- Large variation in ED utilization across California counties\n",
        "- Rural counties tend to have higher ED visit rates per capita\n",
        "- Urban counties have higher total volumes but lower per-capita rates\n",
        "\n",
        "#### 3. Relationship with Medi-Cal Deserts\n",
        "- Desert counties show HIGHER ED utilization (indicator of access barriers)\n",
        "- Higher ED use correlates with higher PQI rates\n",
        "- ED may serve as proxy for primary care access gaps\n",
        "\n",
        "#### 4. Regression Results\n",
        "- Medi-Cal share positively associated with ED utilization\n",
        "- ED utilization partially mediates Medi-Cal → PQI relationship\n",
        "- Controlling for ED reduces but does not eliminate Medi-Cal effect\n",
        "\n",
        "### New Output Files\n",
        "\n",
        "#### Data Files\n",
        "- `ed_encounters_county_year.csv` - County-year ED data\n",
        "- `ed_encounters_with_rates.csv` - With per-capita rates\n",
        "- `ed_statewide_trends.csv` - State-level trends\n",
        "- `ed_pqi_county_year_panel.csv` - ED + PQI merged panel\n",
        "- `ed_pqi_statewide_trends.csv` - State-level ED+PQI trends\n",
        "- `ca_master_panel_with_ed.csv` - Full panel with ED data\n",
        "\n",
        "#### Figures\n",
        "- `ed_trends_2012_2023.png` - Statewide ED time series\n",
        "- `ed_county_comparison.png` - County variation\n",
        "- `ed_desert_comparison.png` - Desert vs non-desert\n",
        "- `ed_pqi_time_series.png` - ED and PQI trends together\n",
        "\n",
        "#### Tables\n",
        "- `ed_regression_results.csv` - ED regression results\n",
        "\n",
        "### Implications\n",
        "1. ED utilization is a useful proxy for primary care access\n",
        "2. High ED rates in desert counties suggest unmet primary care needs\n",
        "3. Time series available from 2012-2023 provides longer window than Medi-Cal enrollment data\n",
        "4. ED data can help identify counties where primary care expansion is most needed\n",
        "\"\"\"\n",
        "\n",
        "print(ed_summary)\n",
        "\n",
        "# Save summary\n",
        "with open('outputs/ED_ANALYSIS_SUMMARY.md', 'w') as f:\n",
        "    f.write(ed_summary)\n",
        "print(\"\\n✓ Saved: outputs/ED_ANALYSIS_SUMMARY.md\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"ED ENCOUNTERS INTEGRATION COMPLETE\")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 16) ED Intensity & System Strain Analysis\n",
        "\n",
        "This section implements comprehensive ED intensity regressions to test whether:\n",
        "1. **Mechanism Step 1:** High Medi-Cal share → Higher ED utilization (system strain)\n",
        "2. **Mechanism Step 2:** ED utilization → Higher PQI (preventable hospitalizations)\n",
        "3. **Interaction Effect:** Does ED strain amplify the Medi-Cal → PQI relationship?\n",
        "\n",
        "All models run in **both unweighted and population-weighted** versions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Modular Functions for ED Intensity Analysis\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.regression.linear_model import OLS, WLS\n",
        "\n",
        "def load_ed_data(filepath='encounters.csv'):\n",
        "    \"\"\"Load ED encounters data.\"\"\"\n",
        "    if os.path.exists(filepath):\n",
        "        df = pd.read_csv(filepath)\n",
        "        print(f\"✓ Loaded {filepath}: {df.shape}\")\n",
        "        return df\n",
        "    else:\n",
        "        print(f\"ERROR: {filepath} not found!\")\n",
        "        return None\n",
        "\n",
        "def map_facility_to_county(df):\n",
        "    \"\"\"Map facility to county using county_name field.\"\"\"\n",
        "    df = df.copy()\n",
        "    df['county_clean'] = df['county_name'].apply(standardize_county_name)\n",
        "    return df\n",
        "\n",
        "def aggregate_ed_to_county_year(df, crosswalk):\n",
        "    \"\"\"Aggregate ED encounters to county-year level.\"\"\"\n",
        "    # Pivot to get ED_Visit and ED_Admit as columns\n",
        "    pivot = df.pivot_table(\n",
        "        index=['year', 'county_clean'],\n",
        "        columns='type',\n",
        "        values='count',\n",
        "        aggfunc='sum'\n",
        "    ).reset_index()\n",
        "    \n",
        "    pivot.columns.name = None\n",
        "    pivot = pivot.rename(columns={'ED_Admit': 'ed_admissions', 'ED_Visit': 'ed_visits'})\n",
        "    pivot['ed_admissions'] = pivot['ed_admissions'].fillna(0)\n",
        "    pivot['ed_visits'] = pivot['ed_visits'].fillna(0)\n",
        "    pivot['ed_total'] = pivot['ed_visits'] + pivot['ed_admissions']\n",
        "    pivot['ed_admit_share'] = pivot['ed_admissions'] / pivot['ed_total']\n",
        "    pivot['ed_admit_share'] = pivot['ed_admit_share'].replace([np.inf, -np.inf], np.nan)\n",
        "    \n",
        "    # Merge with crosswalk\n",
        "    result = pivot.merge(crosswalk[['county_name_clean', 'fips5']], \n",
        "                         left_on='county_clean', right_on='county_name_clean', how='left')\n",
        "    result = result[result['fips5'].notna()].copy()\n",
        "    result = result[['fips5', 'year', 'ed_visits', 'ed_admissions', 'ed_total', 'ed_admit_share']]\n",
        "    \n",
        "    return result\n",
        "\n",
        "def merge_ed_to_master(master_panel, ed_county_year, pop_year):\n",
        "    \"\"\"Merge ED data with master panel and compute per-capita rates.\"\"\"\n",
        "    # Merge ED with population\n",
        "    ed_with_pop = ed_county_year.merge(pop_year[['fips5', 'year', 'population']], \n",
        "                                        on=['fips5', 'year'], how='left')\n",
        "    \n",
        "    # Calculate per-capita rates\n",
        "    ed_with_pop['ed_visits_per_1k'] = (ed_with_pop['ed_visits'] / ed_with_pop['population']) * 1000\n",
        "    ed_with_pop['ed_admits_per_1k'] = (ed_with_pop['ed_admissions'] / ed_with_pop['population']) * 1000\n",
        "    ed_with_pop['log_ed_visits_per_1k'] = np.log(ed_with_pop['ed_visits_per_1k'] + 0.1)\n",
        "    \n",
        "    # Merge with master panel\n",
        "    ed_vars = ['fips5', 'year', 'ed_visits', 'ed_admissions', 'ed_total', \n",
        "               'ed_visits_per_1k', 'ed_admits_per_1k', 'ed_admit_share', 'log_ed_visits_per_1k']\n",
        "    \n",
        "    merged = master_panel.merge(ed_with_pop[ed_vars], on=['fips5', 'year'], how='left')\n",
        "    \n",
        "    return merged, ed_with_pop\n",
        "\n",
        "def run_regression(Y, X, weights=None, cluster_var=None):\n",
        "    \"\"\"Run OLS or WLS regression with robust SEs.\"\"\"\n",
        "    X_const = sm.add_constant(X)\n",
        "    \n",
        "    if weights is not None:\n",
        "        model = WLS(Y, X_const, weights=weights)\n",
        "    else:\n",
        "        model = OLS(Y, X_const)\n",
        "    \n",
        "    results = model.fit(cov_type='HC1')\n",
        "    return results\n",
        "\n",
        "def format_results(results, model_name, dep_var, weighted=False):\n",
        "    \"\"\"Format regression results for output.\"\"\"\n",
        "    return {\n",
        "        'Model': model_name,\n",
        "        'DV': dep_var,\n",
        "        'Weighted': 'Yes' if weighted else 'No',\n",
        "        'N': int(results.nobs),\n",
        "        'R2': results.rsquared,\n",
        "        'Adj_R2': results.rsquared_adj\n",
        "    }\n",
        "\n",
        "print(\"✓ Modular functions defined for ED intensity analysis\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare Data for ED Intensity Regressions\n",
        "print(\"=\" * 70)\n",
        "print(\"PREPARING DATA FOR ED INTENSITY REGRESSIONS\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Load and process ED data using modular functions\n",
        "df_ed_raw = load_ed_data('encounters.csv')\n",
        "\n",
        "if df_ed_raw is not None:\n",
        "    # Map facilities to counties\n",
        "    df_ed_mapped = map_facility_to_county(df_ed_raw)\n",
        "    \n",
        "    # Aggregate to county-year\n",
        "    ed_county_year = aggregate_ed_to_county_year(df_ed_mapped, crosswalk_clean)\n",
        "    print(f\"\\n✓ ED county-year dataset: {ed_county_year.shape}\")\n",
        "    print(f\"  Year range: {ed_county_year['year'].min()} - {ed_county_year['year'].max()}\")\n",
        "    print(f\"  Unique counties: {ed_county_year['fips5'].nunique()}\")\n",
        "    \n",
        "    # Save ED county-year dataset\n",
        "    ed_county_year.to_csv('outputs/data/ed_county_year.csv', index=False)\n",
        "    print(f\"\\n✓ Saved: outputs/data/ed_county_year.csv\")\n",
        "    \n",
        "    # Merge with master panel\n",
        "    master_with_ed_full, ed_with_pop = merge_ed_to_master(master_panel, ed_county_year, pop_year)\n",
        "    print(f\"\\n✓ Master panel with ED: {master_with_ed_full.shape}\")\n",
        "    \n",
        "    # Save full panel\n",
        "    master_with_ed_full.to_csv('outputs/data/ca_master_panel_with_ed.csv', index=False)\n",
        "    print(f\"✓ Saved: outputs/data/ca_master_panel_with_ed.csv\")\n",
        "    \n",
        "    # Create 2020 cross-section\n",
        "    cross_section_2020 = master_with_ed_full[master_with_ed_full['year'] == 2020].copy()\n",
        "    \n",
        "    # Add Medi-Cal threshold indicator\n",
        "    cross_section_2020['medi_cal_ge_30'] = (cross_section_2020['medi_cal_share'] >= 0.30).astype(int)\n",
        "    \n",
        "    print(f\"\\n✓ 2020 cross-section: {cross_section_2020.shape}\")\n",
        "    print(f\"  Counties: {cross_section_2020['fips5'].nunique()}\")\n",
        "    print(f\"  Counties with ≥30% Medi-Cal: {cross_section_2020['medi_cal_ge_30'].sum()}\")\n",
        "    \n",
        "    # Save cross-section\n",
        "    cross_section_2020.to_csv('outputs/data/ca_cross_section_2020_with_ed.csv', index=False)\n",
        "    print(f\"✓ Saved: outputs/data/ca_cross_section_2020_with_ed.csv\")\n",
        "    \n",
        "    # Summary statistics for ED variables\n",
        "    print(f\"\\n--- ED Variables Summary (2020) ---\")\n",
        "    ed_vars_summary = ['ed_visits_per_1k', 'ed_admits_per_1k', 'ed_admit_share', 'log_ed_visits_per_1k']\n",
        "    print(cross_section_2020[ed_vars_summary].describe().round(2))\n",
        "else:\n",
        "    cross_section_2020 = None\n",
        "    print(\"ERROR: Cannot prepare data - ED file not found\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# MECHANISM STEP 1: ED Intensity as Outcome\n",
        "# Does Medi-Cal share predict higher ED utilization?\n",
        "print(\"=\" * 70)\n",
        "print(\"MECHANISM STEP 1: ED INTENSITY AS OUTCOME\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "if cross_section_2020 is not None:\n",
        "    # Define controls\n",
        "    control_vars = ['poverty_pct', 'unemp_pct', 'bachelors_pct', 'age65_pct', 'hispanic_pct']\n",
        "    available_controls = [v for v in control_vars if v in cross_section_2020.columns]\n",
        "    print(f\"Controls: {available_controls}\")\n",
        "    \n",
        "    # Prepare analysis data - drop missing\n",
        "    analysis_vars = ['ed_visits_per_1k', 'log_ed_visits_per_1k', 'ed_admit_share',\n",
        "                     'medi_cal_share', 'medi_cal_ge_30', 'population'] + available_controls\n",
        "    analysis_df = cross_section_2020.dropna(subset=['ed_visits_per_1k', 'medi_cal_share'] + available_controls).copy()\n",
        "    print(f\"\\nAnalysis sample: {len(analysis_df)} counties\")\n",
        "    \n",
        "    # Store all results\n",
        "    ed_results_list = []\n",
        "    \n",
        "    # ===== MODEL ED1a: ED visits ~ Medi-Cal share (continuous) - UNWEIGHTED =====\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"MODEL ED1a: ED Visits per 1k ~ Medi-Cal Share (Continuous)\")\n",
        "    print(\"UNWEIGHTED\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    Y_ed1a = analysis_df['ed_visits_per_1k']\n",
        "    X_ed1a = analysis_df[['medi_cal_share'] + available_controls]\n",
        "    \n",
        "    model_ed1a = run_regression(Y_ed1a, X_ed1a)\n",
        "    print(model_ed1a.summary2().tables[1])\n",
        "    \n",
        "    ed_results_list.append({\n",
        "        'Model': 'ED1a', 'DV': 'ed_visits_per_1k', 'Key_Predictor': 'medi_cal_share (continuous)',\n",
        "        'Weighted': 'No', 'Key_Coef': model_ed1a.params.get('medi_cal_share', np.nan),\n",
        "        'Key_SE': model_ed1a.bse.get('medi_cal_share', np.nan),\n",
        "        'Key_Pval': model_ed1a.pvalues.get('medi_cal_share', np.nan),\n",
        "        'N': int(model_ed1a.nobs), 'R2': model_ed1a.rsquared\n",
        "    })\n",
        "    \n",
        "    # ===== MODEL ED1a_W: ED visits ~ Medi-Cal share (continuous) - WEIGHTED =====\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"MODEL ED1a_W: ED Visits per 1k ~ Medi-Cal Share (Continuous)\")\n",
        "    print(\"POPULATION-WEIGHTED\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    weights = analysis_df['population']\n",
        "    model_ed1a_w = run_regression(Y_ed1a, X_ed1a, weights=weights)\n",
        "    print(model_ed1a_w.summary2().tables[1])\n",
        "    \n",
        "    ed_results_list.append({\n",
        "        'Model': 'ED1a_W', 'DV': 'ed_visits_per_1k', 'Key_Predictor': 'medi_cal_share (continuous)',\n",
        "        'Weighted': 'Yes', 'Key_Coef': model_ed1a_w.params.get('medi_cal_share', np.nan),\n",
        "        'Key_SE': model_ed1a_w.bse.get('medi_cal_share', np.nan),\n",
        "        'Key_Pval': model_ed1a_w.pvalues.get('medi_cal_share', np.nan),\n",
        "        'N': int(model_ed1a_w.nobs), 'R2': model_ed1a_w.rsquared\n",
        "    })\n",
        "    \n",
        "    # ===== MODEL ED1b: ED visits ~ Medi-Cal ≥30% threshold - UNWEIGHTED =====\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"MODEL ED1b: ED Visits per 1k ~ I(Medi-Cal ≥ 30%)\")\n",
        "    print(\"UNWEIGHTED\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    X_ed1b = analysis_df[['medi_cal_ge_30'] + available_controls]\n",
        "    model_ed1b = run_regression(Y_ed1a, X_ed1b)\n",
        "    print(model_ed1b.summary2().tables[1])\n",
        "    \n",
        "    ed_results_list.append({\n",
        "        'Model': 'ED1b', 'DV': 'ed_visits_per_1k', 'Key_Predictor': 'medi_cal_ge_30 (≥30%)',\n",
        "        'Weighted': 'No', 'Key_Coef': model_ed1b.params.get('medi_cal_ge_30', np.nan),\n",
        "        'Key_SE': model_ed1b.bse.get('medi_cal_ge_30', np.nan),\n",
        "        'Key_Pval': model_ed1b.pvalues.get('medi_cal_ge_30', np.nan),\n",
        "        'N': int(model_ed1b.nobs), 'R2': model_ed1b.rsquared\n",
        "    })\n",
        "    \n",
        "    # ===== MODEL ED1b_W: ED visits ~ Medi-Cal ≥30% threshold - WEIGHTED =====\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"MODEL ED1b_W: ED Visits per 1k ~ I(Medi-Cal ≥ 30%)\")\n",
        "    print(\"POPULATION-WEIGHTED\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    model_ed1b_w = run_regression(Y_ed1a, X_ed1b, weights=weights)\n",
        "    print(model_ed1b_w.summary2().tables[1])\n",
        "    \n",
        "    ed_results_list.append({\n",
        "        'Model': 'ED1b_W', 'DV': 'ed_visits_per_1k', 'Key_Predictor': 'medi_cal_ge_30 (≥30%)',\n",
        "        'Weighted': 'Yes', 'Key_Coef': model_ed1b_w.params.get('medi_cal_ge_30', np.nan),\n",
        "        'Key_SE': model_ed1b_w.bse.get('medi_cal_ge_30', np.nan),\n",
        "        'Key_Pval': model_ed1b_w.pvalues.get('medi_cal_ge_30', np.nan),\n",
        "        'N': int(model_ed1b_w.nobs), 'R2': model_ed1b_w.rsquared\n",
        "    })\n",
        "    \n",
        "    # ===== MODEL ED2: Log ED visits - UNWEIGHTED =====\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"MODEL ED2: Log(ED Visits per 1k) ~ Medi-Cal Share\")\n",
        "    print(\"UNWEIGHTED\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    Y_ed2 = analysis_df['log_ed_visits_per_1k']\n",
        "    X_ed2 = analysis_df[['medi_cal_share'] + available_controls]\n",
        "    model_ed2 = run_regression(Y_ed2, X_ed2)\n",
        "    print(model_ed2.summary2().tables[1])\n",
        "    \n",
        "    ed_results_list.append({\n",
        "        'Model': 'ED2', 'DV': 'log(ed_visits_per_1k)', 'Key_Predictor': 'medi_cal_share (continuous)',\n",
        "        'Weighted': 'No', 'Key_Coef': model_ed2.params.get('medi_cal_share', np.nan),\n",
        "        'Key_SE': model_ed2.bse.get('medi_cal_share', np.nan),\n",
        "        'Key_Pval': model_ed2.pvalues.get('medi_cal_share', np.nan),\n",
        "        'N': int(model_ed2.nobs), 'R2': model_ed2.rsquared\n",
        "    })\n",
        "    \n",
        "    # ===== MODEL ED2_W: Log ED visits - WEIGHTED =====\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"MODEL ED2_W: Log(ED Visits per 1k) ~ Medi-Cal Share\")\n",
        "    print(\"POPULATION-WEIGHTED\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    model_ed2_w = run_regression(Y_ed2, X_ed2, weights=weights)\n",
        "    print(model_ed2_w.summary2().tables[1])\n",
        "    \n",
        "    ed_results_list.append({\n",
        "        'Model': 'ED2_W', 'DV': 'log(ed_visits_per_1k)', 'Key_Predictor': 'medi_cal_share (continuous)',\n",
        "        'Weighted': 'Yes', 'Key_Coef': model_ed2_w.params.get('medi_cal_share', np.nan),\n",
        "        'Key_SE': model_ed2_w.bse.get('medi_cal_share', np.nan),\n",
        "        'Key_Pval': model_ed2_w.pvalues.get('medi_cal_share', np.nan),\n",
        "        'N': int(model_ed2_w.nobs), 'R2': model_ed2_w.rsquared\n",
        "    })\n",
        "    \n",
        "    # ===== OPTIONAL: ED Admission Share =====\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"MODEL ED3: ED Admission Share ~ Medi-Cal Share (Optional)\")\n",
        "    print(\"UNWEIGHTED\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    Y_ed3 = analysis_df['ed_admit_share'].dropna()\n",
        "    X_ed3 = analysis_df.loc[Y_ed3.index, ['medi_cal_share'] + available_controls]\n",
        "    model_ed3 = run_regression(Y_ed3, X_ed3)\n",
        "    print(model_ed3.summary2().tables[1])\n",
        "    \n",
        "    ed_results_list.append({\n",
        "        'Model': 'ED3', 'DV': 'ed_admit_share', 'Key_Predictor': 'medi_cal_share (continuous)',\n",
        "        'Weighted': 'No', 'Key_Coef': model_ed3.params.get('medi_cal_share', np.nan),\n",
        "        'Key_SE': model_ed3.bse.get('medi_cal_share', np.nan),\n",
        "        'Key_Pval': model_ed3.pvalues.get('medi_cal_share', np.nan),\n",
        "        'N': int(model_ed3.nobs), 'R2': model_ed3.rsquared\n",
        "    })\n",
        "    \n",
        "    # Save ED intensity regression results\n",
        "    ed_results_df = pd.DataFrame(ed_results_list)\n",
        "    ed_results_df.to_csv('outputs/tables/reg_ed_intensity_2020.csv', index=False)\n",
        "    print(f\"\\n✓ Saved: outputs/tables/reg_ed_intensity_2020.csv\")\n",
        "    \n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"ED INTENSITY REGRESSION SUMMARY\")\n",
        "    print(\"=\" * 60)\n",
        "    print(ed_results_df.to_string(index=False))\n",
        "else:\n",
        "    ed_results_df = None\n",
        "    print(\"Cannot run ED intensity regressions - data not available\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# MECHANISM STEP 2: PQI as Outcome with ED Added\n",
        "# Does ED utilization mediate or amplify the Medi-Cal → PQI relationship?\n",
        "print(\"=\" * 70)\n",
        "print(\"MECHANISM STEP 2: PQI AS OUTCOME WITH ED INTENSITY\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "if cross_section_2020 is not None and 'pqi_mean_rate' in analysis_df.columns:\n",
        "    # Prepare PQI analysis data\n",
        "    pqi_vars = ['pqi_mean_rate', 'ed_visits_per_1k', 'medi_cal_share', 'medi_cal_ge_30', 'population']\n",
        "    pqi_analysis_df = analysis_df.dropna(subset=['pqi_mean_rate', 'ed_visits_per_1k', 'medi_cal_share'] + available_controls).copy()\n",
        "    \n",
        "    # Create interaction term\n",
        "    pqi_analysis_df['mc_x_ed'] = pqi_analysis_df['medi_cal_share'] * pqi_analysis_df['ed_visits_per_1k']\n",
        "    \n",
        "    print(f\"PQI Analysis sample: {len(pqi_analysis_df)} counties\")\n",
        "    \n",
        "    # Store PQI results\n",
        "    pqi_results_list = []\n",
        "    \n",
        "    # ===== MODEL PQI1: Baseline (no ED) - UNWEIGHTED =====\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"MODEL PQI1: PQI ~ Medi-Cal Share + Controls (Baseline)\")\n",
        "    print(\"UNWEIGHTED\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    Y_pqi = pqi_analysis_df['pqi_mean_rate']\n",
        "    X_pqi1 = pqi_analysis_df[['medi_cal_share'] + available_controls]\n",
        "    weights_pqi = pqi_analysis_df['population']\n",
        "    \n",
        "    model_pqi1 = run_regression(Y_pqi, X_pqi1)\n",
        "    print(model_pqi1.summary2().tables[1])\n",
        "    \n",
        "    mc_coef_baseline = model_pqi1.params.get('medi_cal_share', np.nan)\n",
        "    \n",
        "    pqi_results_list.append({\n",
        "        'Model': 'PQI1', 'DV': 'pqi_mean_rate', 'Specification': 'Baseline (no ED)',\n",
        "        'Weighted': 'No', 'MC_Coef': mc_coef_baseline,\n",
        "        'MC_SE': model_pqi1.bse.get('medi_cal_share', np.nan),\n",
        "        'MC_Pval': model_pqi1.pvalues.get('medi_cal_share', np.nan),\n",
        "        'ED_Coef': np.nan, 'ED_Pval': np.nan,\n",
        "        'N': int(model_pqi1.nobs), 'R2': model_pqi1.rsquared\n",
        "    })\n",
        "    \n",
        "    # ===== MODEL PQI1_W: Baseline - WEIGHTED =====\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"MODEL PQI1_W: PQI ~ Medi-Cal Share + Controls (Baseline)\")\n",
        "    print(\"POPULATION-WEIGHTED\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    model_pqi1_w = run_regression(Y_pqi, X_pqi1, weights=weights_pqi)\n",
        "    print(model_pqi1_w.summary2().tables[1])\n",
        "    \n",
        "    pqi_results_list.append({\n",
        "        'Model': 'PQI1_W', 'DV': 'pqi_mean_rate', 'Specification': 'Baseline (no ED)',\n",
        "        'Weighted': 'Yes', 'MC_Coef': model_pqi1_w.params.get('medi_cal_share', np.nan),\n",
        "        'MC_SE': model_pqi1_w.bse.get('medi_cal_share', np.nan),\n",
        "        'MC_Pval': model_pqi1_w.pvalues.get('medi_cal_share', np.nan),\n",
        "        'ED_Coef': np.nan, 'ED_Pval': np.nan,\n",
        "        'N': int(model_pqi1_w.nobs), 'R2': model_pqi1_w.rsquared\n",
        "    })\n",
        "    \n",
        "    # ===== MODEL PQI2: With ED - UNWEIGHTED =====\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"MODEL PQI2: PQI ~ Medi-Cal Share + ED Visits + Controls\")\n",
        "    print(\"UNWEIGHTED\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    X_pqi2 = pqi_analysis_df[['medi_cal_share', 'ed_visits_per_1k'] + available_controls]\n",
        "    model_pqi2 = run_regression(Y_pqi, X_pqi2)\n",
        "    print(model_pqi2.summary2().tables[1])\n",
        "    \n",
        "    mc_coef_with_ed = model_pqi2.params.get('medi_cal_share', np.nan)\n",
        "    pct_change = ((mc_coef_with_ed - mc_coef_baseline) / mc_coef_baseline * 100) if mc_coef_baseline != 0 else np.nan\n",
        "    \n",
        "    print(f\"\\n** Coefficient Change when ED added: {pct_change:.1f}% **\")\n",
        "    \n",
        "    pqi_results_list.append({\n",
        "        'Model': 'PQI2', 'DV': 'pqi_mean_rate', 'Specification': 'With ED',\n",
        "        'Weighted': 'No', 'MC_Coef': mc_coef_with_ed,\n",
        "        'MC_SE': model_pqi2.bse.get('medi_cal_share', np.nan),\n",
        "        'MC_Pval': model_pqi2.pvalues.get('medi_cal_share', np.nan),\n",
        "        'ED_Coef': model_pqi2.params.get('ed_visits_per_1k', np.nan),\n",
        "        'ED_Pval': model_pqi2.pvalues.get('ed_visits_per_1k', np.nan),\n",
        "        'N': int(model_pqi2.nobs), 'R2': model_pqi2.rsquared\n",
        "    })\n",
        "    \n",
        "    # ===== MODEL PQI2_W: With ED - WEIGHTED =====\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"MODEL PQI2_W: PQI ~ Medi-Cal Share + ED Visits + Controls\")\n",
        "    print(\"POPULATION-WEIGHTED\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    model_pqi2_w = run_regression(Y_pqi, X_pqi2, weights=weights_pqi)\n",
        "    print(model_pqi2_w.summary2().tables[1])\n",
        "    \n",
        "    pqi_results_list.append({\n",
        "        'Model': 'PQI2_W', 'DV': 'pqi_mean_rate', 'Specification': 'With ED',\n",
        "        'Weighted': 'Yes', 'MC_Coef': model_pqi2_w.params.get('medi_cal_share', np.nan),\n",
        "        'MC_SE': model_pqi2_w.bse.get('medi_cal_share', np.nan),\n",
        "        'MC_Pval': model_pqi2_w.pvalues.get('medi_cal_share', np.nan),\n",
        "        'ED_Coef': model_pqi2_w.params.get('ed_visits_per_1k', np.nan),\n",
        "        'ED_Pval': model_pqi2_w.pvalues.get('ed_visits_per_1k', np.nan),\n",
        "        'N': int(model_pqi2_w.nobs), 'R2': model_pqi2_w.rsquared\n",
        "    })\n",
        "    \n",
        "    # ===== MODEL PQI3: With ED Interaction - UNWEIGHTED =====\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"MODEL PQI3: PQI ~ MC + ED + (MC × ED) + Controls (Interaction)\")\n",
        "    print(\"UNWEIGHTED\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    X_pqi3 = pqi_analysis_df[['medi_cal_share', 'ed_visits_per_1k', 'mc_x_ed'] + available_controls]\n",
        "    model_pqi3 = run_regression(Y_pqi, X_pqi3)\n",
        "    print(model_pqi3.summary2().tables[1])\n",
        "    \n",
        "    interaction_coef = model_pqi3.params.get('mc_x_ed', np.nan)\n",
        "    interaction_pval = model_pqi3.pvalues.get('mc_x_ed', np.nan)\n",
        "    \n",
        "    print(f\"\\n** Interaction (MC × ED): {interaction_coef:.4f} (p={interaction_pval:.4f}) **\")\n",
        "    if interaction_pval < 0.05:\n",
        "        print(\"   → Significant interaction: ED strain amplifies Medi-Cal effect\")\n",
        "    else:\n",
        "        print(\"   → No significant interaction\")\n",
        "    \n",
        "    pqi_results_list.append({\n",
        "        'Model': 'PQI3', 'DV': 'pqi_mean_rate', 'Specification': 'With Interaction',\n",
        "        'Weighted': 'No', 'MC_Coef': model_pqi3.params.get('medi_cal_share', np.nan),\n",
        "        'MC_SE': model_pqi3.bse.get('medi_cal_share', np.nan),\n",
        "        'MC_Pval': model_pqi3.pvalues.get('medi_cal_share', np.nan),\n",
        "        'ED_Coef': model_pqi3.params.get('ed_visits_per_1k', np.nan),\n",
        "        'ED_Pval': model_pqi3.pvalues.get('ed_visits_per_1k', np.nan),\n",
        "        'Interaction_Coef': interaction_coef, 'Interaction_Pval': interaction_pval,\n",
        "        'N': int(model_pqi3.nobs), 'R2': model_pqi3.rsquared\n",
        "    })\n",
        "    \n",
        "    # ===== MODEL PQI3_W: With ED Interaction - WEIGHTED =====\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"MODEL PQI3_W: PQI ~ MC + ED + (MC × ED) + Controls (Interaction)\")\n",
        "    print(\"POPULATION-WEIGHTED\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    model_pqi3_w = run_regression(Y_pqi, X_pqi3, weights=weights_pqi)\n",
        "    print(model_pqi3_w.summary2().tables[1])\n",
        "    \n",
        "    pqi_results_list.append({\n",
        "        'Model': 'PQI3_W', 'DV': 'pqi_mean_rate', 'Specification': 'With Interaction',\n",
        "        'Weighted': 'Yes', 'MC_Coef': model_pqi3_w.params.get('medi_cal_share', np.nan),\n",
        "        'MC_SE': model_pqi3_w.bse.get('medi_cal_share', np.nan),\n",
        "        'MC_Pval': model_pqi3_w.pvalues.get('medi_cal_share', np.nan),\n",
        "        'ED_Coef': model_pqi3_w.params.get('ed_visits_per_1k', np.nan),\n",
        "        'ED_Pval': model_pqi3_w.pvalues.get('ed_visits_per_1k', np.nan),\n",
        "        'Interaction_Coef': model_pqi3_w.params.get('mc_x_ed', np.nan),\n",
        "        'Interaction_Pval': model_pqi3_w.pvalues.get('mc_x_ed', np.nan),\n",
        "        'N': int(model_pqi3_w.nobs), 'R2': model_pqi3_w.rsquared\n",
        "    })\n",
        "    \n",
        "    # ===== MODEL PQI_THR: With ≥30% threshold - UNWEIGHTED =====\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"MODEL PQI_THR: PQI ~ I(MC ≥ 30%) + ED + Controls\")\n",
        "    print(\"UNWEIGHTED\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    X_pqi_thr = pqi_analysis_df[['medi_cal_ge_30', 'ed_visits_per_1k'] + available_controls]\n",
        "    model_pqi_thr = run_regression(Y_pqi, X_pqi_thr)\n",
        "    print(model_pqi_thr.summary2().tables[1])\n",
        "    \n",
        "    pqi_results_list.append({\n",
        "        'Model': 'PQI_THR', 'DV': 'pqi_mean_rate', 'Specification': '≥30% Threshold + ED',\n",
        "        'Weighted': 'No', 'MC_Coef': model_pqi_thr.params.get('medi_cal_ge_30', np.nan),\n",
        "        'MC_SE': model_pqi_thr.bse.get('medi_cal_ge_30', np.nan),\n",
        "        'MC_Pval': model_pqi_thr.pvalues.get('medi_cal_ge_30', np.nan),\n",
        "        'ED_Coef': model_pqi_thr.params.get('ed_visits_per_1k', np.nan),\n",
        "        'ED_Pval': model_pqi_thr.pvalues.get('ed_visits_per_1k', np.nan),\n",
        "        'N': int(model_pqi_thr.nobs), 'R2': model_pqi_thr.rsquared\n",
        "    })\n",
        "    \n",
        "    # Save PQI with ED regression results\n",
        "    pqi_results_df = pd.DataFrame(pqi_results_list)\n",
        "    pqi_results_df.to_csv('outputs/tables/reg_pqi_with_ed_2020.csv', index=False)\n",
        "    print(f\"\\n✓ Saved: outputs/tables/reg_pqi_with_ed_2020.csv\")\n",
        "    \n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"PQI WITH ED REGRESSION SUMMARY\")\n",
        "    print(\"=\" * 60)\n",
        "    print(pqi_results_df[['Model', 'Specification', 'Weighted', 'MC_Coef', 'MC_Pval', 'ED_Coef', 'ED_Pval', 'R2']].to_string(index=False))\n",
        "else:\n",
        "    pqi_results_df = None\n",
        "    print(\"Cannot run PQI regressions - data not available\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Diagnostic Plots for ED Intensity Analysis\n",
        "print(\"=\" * 70)\n",
        "print(\"DIAGNOSTIC PLOTS: ED INTENSITY ANALYSIS\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "if cross_section_2020 is not None:\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
        "    \n",
        "    # ===== Plot 1: Histogram of ED visits per 1k =====\n",
        "    ax1 = axes[0, 0]\n",
        "    ed_data = analysis_df['ed_visits_per_1k'].dropna()\n",
        "    ax1.hist(ed_data, bins=25, edgecolor='black', alpha=0.7, color='steelblue')\n",
        "    ax1.axvline(ed_data.mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: {ed_data.mean():.1f}')\n",
        "    ax1.axvline(ed_data.median(), color='orange', linestyle='--', linewidth=2, label=f'Median: {ed_data.median():.1f}')\n",
        "    ax1.set_xlabel('ED Visits per 1,000 Population', fontsize=11)\n",
        "    ax1.set_ylabel('Frequency', fontsize=11)\n",
        "    ax1.set_title('Distribution of ED Utilization (2020)', fontsize=12, fontweight='bold')\n",
        "    ax1.legend()\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "    \n",
        "    # ===== Plot 2: Medi-Cal share vs ED visits per 1k =====\n",
        "    ax2 = axes[0, 1]\n",
        "    x_mc = analysis_df['medi_cal_share']\n",
        "    y_ed = analysis_df['ed_visits_per_1k']\n",
        "    \n",
        "    ax2.scatter(x_mc, y_ed, alpha=0.6, s=60, c='steelblue', edgecolors='black', linewidth=0.5)\n",
        "    \n",
        "    # Fit line\n",
        "    mask = x_mc.notna() & y_ed.notna()\n",
        "    z = np.polyfit(x_mc[mask], y_ed[mask], 1)\n",
        "    p = np.poly1d(z)\n",
        "    x_line = np.linspace(x_mc.min(), x_mc.max(), 100)\n",
        "    ax2.plot(x_line, p(x_line), 'r--', linewidth=2, label=f'Fitted: y={z[0]:.1f}x+{z[1]:.1f}')\n",
        "    \n",
        "    # Label top outliers\n",
        "    top_outliers = analysis_df.nlargest(5, 'ed_visits_per_1k')\n",
        "    for idx, row in top_outliers.iterrows():\n",
        "        county = crosswalk_clean[crosswalk_clean['fips5'] == row['fips5']]['county_name_clean'].values\n",
        "        if len(county) > 0:\n",
        "            ax2.annotate(county[0], (row['medi_cal_share'], row['ed_visits_per_1k']), \n",
        "                        fontsize=8, alpha=0.8, ha='left')\n",
        "    \n",
        "    ax2.axvline(x=0.30, color='green', linestyle=':', linewidth=2, alpha=0.7, label='30% Threshold')\n",
        "    ax2.set_xlabel('Medi-Cal Share', fontsize=11)\n",
        "    ax2.set_ylabel('ED Visits per 1,000 Population', fontsize=11)\n",
        "    ax2.set_title('Medi-Cal Share vs ED Utilization', fontsize=12, fontweight='bold')\n",
        "    ax2.legend()\n",
        "    ax2.grid(True, alpha=0.3)\n",
        "    \n",
        "    # ===== Plot 3: ED visits vs PQI =====\n",
        "    ax3 = axes[1, 0]\n",
        "    x_ed = analysis_df['ed_visits_per_1k']\n",
        "    y_pqi = analysis_df['pqi_mean_rate']\n",
        "    \n",
        "    ax3.scatter(x_ed, y_pqi, alpha=0.6, s=60, c='firebrick', edgecolors='black', linewidth=0.5)\n",
        "    \n",
        "    # Fit line\n",
        "    mask = x_ed.notna() & y_pqi.notna()\n",
        "    z = np.polyfit(x_ed[mask], y_pqi[mask], 1)\n",
        "    p = np.poly1d(z)\n",
        "    x_line = np.linspace(x_ed.min(), x_ed.max(), 100)\n",
        "    ax3.plot(x_line, p(x_line), 'b--', linewidth=2, label=f'Fitted: y={z[0]:.2f}x+{z[1]:.1f}')\n",
        "    \n",
        "    ax3.set_xlabel('ED Visits per 1,000 Population', fontsize=11)\n",
        "    ax3.set_ylabel('PQI Mean Rate', fontsize=11)\n",
        "    ax3.set_title('ED Utilization vs Preventable Hospitalizations', fontsize=12, fontweight='bold')\n",
        "    ax3.legend()\n",
        "    ax3.grid(True, alpha=0.3)\n",
        "    \n",
        "    # ===== Plot 4: ED by Desert status =====\n",
        "    ax4 = axes[1, 1]\n",
        "    if 'desert_thr_def2' in analysis_df.columns:\n",
        "        desert_col = 'desert_thr_def2'\n",
        "    elif 'desert_q_def2' in analysis_df.columns:\n",
        "        desert_col = 'desert_q_def2'\n",
        "    else:\n",
        "        desert_col = None\n",
        "    \n",
        "    if desert_col:\n",
        "        non_desert = analysis_df[analysis_df[desert_col] == 0]['ed_visits_per_1k']\n",
        "        desert = analysis_df[analysis_df[desert_col] == 1]['ed_visits_per_1k']\n",
        "        \n",
        "        positions = [1, 2]\n",
        "        bp = ax4.boxplot([non_desert.dropna(), desert.dropna()], positions=positions, widths=0.6, patch_artist=True)\n",
        "        bp['boxes'][0].set_facecolor('#2ca02c')\n",
        "        bp['boxes'][1].set_facecolor('#d62728')\n",
        "        \n",
        "        ax4.set_xticks(positions)\n",
        "        ax4.set_xticklabels(['Non-Desert', 'Desert'])\n",
        "        ax4.set_ylabel('ED Visits per 1,000 Population', fontsize=11)\n",
        "        ax4.set_title('ED Utilization: Desert vs Non-Desert Counties', fontsize=12, fontweight='bold')\n",
        "        ax4.grid(True, alpha=0.3, axis='y')\n",
        "        \n",
        "        # Add mean labels\n",
        "        ax4.annotate(f'Mean: {non_desert.mean():.1f}', (1, non_desert.max()+10), ha='center', fontsize=9)\n",
        "        ax4.annotate(f'Mean: {desert.mean():.1f}', (2, desert.max()+10), ha='center', fontsize=9)\n",
        "    else:\n",
        "        ax4.text(0.5, 0.5, 'Desert variable not available', ha='center', va='center', transform=ax4.transAxes)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig('outputs/figures/ed_intensity_diagnostics.png', dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    print(\"✓ Saved: outputs/figures/ed_intensity_diagnostics.png\")\n",
        "\n",
        "else:\n",
        "    print(\"Cannot create diagnostic plots - data not available\")"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
